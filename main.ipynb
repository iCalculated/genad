{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shy/Projects/genad/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading flax_model.msgpack: 100%|██████████| 6.17G/6.17G [27:45<00:00, 3.71MB/s]\n",
      "Downloading generation_config.json: 100%|██████████| 4.29k/4.29k [00:00<00:00, 4.31MB/s]\n"
     ]
    }
   ],
   "source": [
    "from whisper_jax import FlaxWhisperPipline\n",
    "\n",
    "pipeline = FlaxWhisperPipline(\"openai/whisper-large-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'audio.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# JIT compile the forward call - slow, but we only do once\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio.mp3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_timestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# used cached function thereafter - super fast!!\u001b[39;00m\n\u001b[1;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_timestamps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/genad/env/lib/python3.12/site-packages/whisper_jax/pipeline.py:499\u001b[0m, in \u001b[0;36mFlaxWhisperPipline.__call__\u001b[0;34m(self, inputs, chunk_length_s, stride_length_s, batch_size, language, task, return_timestamps, generate_kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# iterate over our chunked audio samples\u001b[39;00m\n\u001b[0;32m--> 499\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_timestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_timestamps\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m post_processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, return_timestamps\u001b[38;5;241m=\u001b[39mreturn_timestamps)\n",
      "File \u001b[0;32m~/Projects/genad/env/lib/python3.12/site-packages/whisper_jax/pipeline.py:295\u001b[0m, in \u001b[0;36mFlaxWhisperPipline.preprocess_batch\u001b[0;34m(self, inputs, chunk_length_s, stride_length_s, batch_size)\u001b[0m\n\u001b[1;32m    293\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(inputs)\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    296\u001b[0m             inputs \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mbytes\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'audio.mp3'"
     ]
    }
   ],
   "source": [
    "# JIT compile the forward call - slow, but we only do once\n",
    "text = pipeline(\"audio.mp3\", return_timestamps=True)\n",
    "\n",
    "# used cached function thereafter - super fast!!\n",
    "text = pipeline(\"audio.mp3\", return_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP4 files in 'data' directory: [PosixPath('data/SettingSlopeGutter1b.mp4'), PosixPath('data/SettingSlopeGutter2.mp4')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Get all files in the 'data' directory using pathlib\n",
    "data_directory = Path('data')\n",
    "mp4_files = [file for file in data_directory.glob('*.mp4')] + [file for file in data_directory.glob('*.MP4')]\n",
    "\n",
    "print(\"MP4 files in 'data' directory:\", mp4_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted MP3 files: [PosixPath('data/mp3/SettingSlopeGutter1b.mp3'), PosixPath('data/mp3/SettingSlopeGutter2.mp3')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/SettingSlopeGutter1b.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    creation_time   : 2023-08-24T19:49:41.000000Z\n",
      "    encoder         : Lavf56.15.102\n",
      "  Duration: 00:01:23.52, start: 0.000000, bitrate: 93052 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main) (hvc1 / 0x31637668), yuv420p(tv), 3840x2160, 93050 kb/s, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-08-24T19:49:41.000000Z\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Output #0, mp3, to 'data/mp3/SettingSlopeGutter1b.mp3':\n",
      "[out#0/mp3 @ 0x123e1bd50] Output file does not contain any stream\n",
      "Error opening output file data/mp3/SettingSlopeGutter1b.mp3.\n",
      "Error opening output files: Invalid argument\n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/SettingSlopeGutter2.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    creation_time   : 2023-08-24T20:07:30.000000Z\n",
      "    encoder         : Lavf56.15.102\n",
      "  Duration: 00:01:25.52, start: 0.000000, bitrate: 93073 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main) (hvc1 / 0x31637668), yuv420p(tv), 3840x2160, 93071 kb/s, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-08-24T20:07:30.000000Z\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "    Side data:\n",
      "      displaymatrix: rotation of 90.00 degrees\n",
      "Output #0, mp3, to 'data/mp3/SettingSlopeGutter2.mp3':\n",
      "[out#0/mp3 @ 0x11e9048d0] Output file does not contain any stream\n",
      "Error opening output file data/mp3/SettingSlopeGutter2.mp3.\n",
      "Error opening output files: Invalid argument\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Function to extract mp3 from mp4\n",
    "def extract_mp3_from_mp4(mp4_file_path, output_directory):\n",
    "    output_mp3_path = output_directory / f\"{mp4_file_path.stem}.mp3\"\n",
    "    command = f\"ffmpeg -i {mp4_file_path} {output_mp3_path}\"\n",
    "    subprocess.run(command, shell=True)\n",
    "    return output_mp3_path\n",
    "\n",
    "# Create a directory for the extracted mp3 files if it doesn't exist\n",
    "mp3_directory = data_directory / 'mp3'\n",
    "mp3_directory.mkdir(exist_ok=True)\n",
    "\n",
    "# Extract mp3 files from each mp4 file\n",
    "extracted_mp3_files = [extract_mp3_from_mp4(mp4_file, mp3_directory) for mp4_file in mp4_files]\n",
    "print(\"Extracted MP3 files:\", extracted_mp3_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe each MP3 file using the Whisper pipeline with timestamps and save the transcripts\n",
    "def transcribe_and_save(mp3_file_path, output_directory):\n",
    "    # Transcribe the audio file with timestamps\n",
    "    transcription_result = pipeline(str(mp3_file_path), return_timestamps=True)\n",
    "    \n",
    "    # Extract text from the transcription result\n",
    "    transcription_text = \"\\n\".join([f\"{segment['start']} - {segment['end']}: {segment['text']}\" for segment in transcription_result['segments']])\n",
    "    \n",
    "    # Define the output path for the transcript\n",
    "    output_transcript_path = output_directory / f\"{mp3_file_path.stem}.txt\"\n",
    "    \n",
    "    # Write the transcription to a file\n",
    "    with open(output_transcript_path, 'w') as file:\n",
    "        file.write(transcription_text)\n",
    "    \n",
    "    return output_transcript_path\n",
    "\n",
    "# Create a directory for the transcripts if it doesn't exist\n",
    "transcript_directory = data_directory / 'transcripts'\n",
    "transcript_directory.mkdir(exist_ok=True)\n",
    "\n",
    "# Transcribe each MP3 file and save the transcripts with timestamps\n",
    "transcribed_files = [transcribe_and_save(mp3_file, transcript_directory) for mp3_file in extracted_mp3_files]\n",
    "print(\"Transcribed files saved with timestamps:\", transcribed_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load OpenAI API key from environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.\")\n",
    "print(\"OpenAI API key loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Load OpenAI API key from environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "def select_storyboard_segments(transcripts, goal):\n",
    "    # Define the prompt for selecting relevant segments\n",
    "    prompt_template = \"Given the goal to '{}', select relevant segments from the following transcript: {}\"\n",
    "    \n",
    "    # Initialize a dictionary to store filenames and their relevant segments\n",
    "    storyboard_segments = {}\n",
    "    \n",
    "    # Iterate over each transcript file\n",
    "    for transcript_file in transcripts:\n",
    "        # Read the transcript content\n",
    "        with open(transcript_file, 'r') as file:\n",
    "            transcript_content = file.read()\n",
    "        \n",
    "        # Create the prompt for GPT\n",
    "        prompt = f\"Given the goal to '{goal}', select relevant segments from the following transcript: {transcript_content}\"\n",
    "        \n",
    "        # Get the response from GPT-4\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"gpt-4o\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=150,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        \n",
    "        # Extract the text from the response\n",
    "        relevant_segments = response.choices[0].text.strip()\n",
    "        \n",
    "        # Store the relevant segments in the dictionary\n",
    "        storyboard_segments[transcript_file] = relevant_segments\n",
    "    \n",
    "    return storyboard_segments\n",
    "\n",
    "# Define the high level goal\n",
    "high_level_goal = \"make an advertising video\"\n",
    "\n",
    "# Select relevant segments for the storyboard\n",
    "storyboard = select_storyboard_segments(transcribed_files, high_level_goal)\n",
    "print(\"Storyboard segments selected:\", json.dumps(storyboard, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "\n",
    "def create_storyboard_video(storyboard, original_video_path):\n",
    "    # Load the original video\n",
    "    original_clip = VideoFileClip(original_video_path)\n",
    "    \n",
    "    # List to hold all the clips to concatenate\n",
    "    clips = []\n",
    "    \n",
    "    # Iterate over the storyboard segments\n",
    "    for start_time, end_time in storyboard.values():\n",
    "        # Extract the clip from the original video based on the start and end times\n",
    "        clip = original_clip.subclip(start_time, end_time)\n",
    "        clips.append(clip)\n",
    "    \n",
    "    # Concatenate all the clips into one final video\n",
    "    final_clip = concatenate_videoclips(clips)\n",
    "    \n",
    "    # Write the result to a file\n",
    "    output_path = \"final_storyboard_video.mp4\"\n",
    "    final_clip.write_videofile(output_path, codec=\"libx264\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Assuming 'original_video_path' is defined and contains the path to the original video\n",
    "final_video_path = create_storyboard_video(storyboard, original_video_path)\n",
    "print(\"Final storyboard video created at:\", final_video_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
