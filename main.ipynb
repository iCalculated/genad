{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)rocessor_config.json: 100%|██████████| 185k/185k [00:00<00:00, 1.44MB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 283k/283k [00:00<00:00, 2.32MB/s]\n",
      "Downloading vocab.json: 100%|██████████| 836k/836k [00:00<00:00, 3.17MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 2.48M/2.48M [00:00<00:00, 8.96MB/s]\n",
      "Downloading merges.txt: 100%|██████████| 494k/494k [00:00<00:00, 3.88MB/s]\n",
      "Downloading normalizer.json: 100%|██████████| 52.7k/52.7k [00:00<00:00, 59.0MB/s]\n",
      "Downloading added_tokens.json: 100%|██████████| 34.6k/34.6k [00:00<00:00, 18.7MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 2.19k/2.19k [00:00<00:00, 6.27MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading config.json: 100%|██████████| 1.98k/1.98k [00:00<00:00, 4.06MB/s]\n",
      "Downloading flax_model.msgpack: 100%|██████████| 151M/151M [00:39<00:00, 3.85MB/s] \n",
      "Downloading generation_config.json: 100%|██████████| 3.75k/3.75k [00:00<00:00, 13.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "from whisper_jax import FlaxWhisperPipline\n",
    "import jax.numpy as jnp\n",
    "\n",
    "model = \"tiny\" # could be \"medium\" or \"large-v2\". medium is probably the most pragmatic balance\n",
    "pipeline = FlaxWhisperPipline(f\"openai/whisper-{model}\", dtype=jnp.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    }
   ],
   "source": [
    "# JIT compile the forward call - slow, but we only do once\n",
    "# testing on a minute long clip\n",
    "text = pipeline(\"output.mp3\", return_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" In the last chapter, you and I started to step through the internal workings of a transformer. This is one of the key pieces of technology inside large language models, and a lot of other tools in the modern way of AI. It first hit the scene and a now-famous 2017 paper called Attention as All You Need, and in this chapter, you and I will dig into what this attention mechanism is, visualizing how it processes data. As a quick recap, here's the important context I want you to have in mind. The goal of the model that you and I are studying is to take in a piece of text and predict what word comes next. The input text is broken up into little pieces that we call tokens, and these are very often words or pieces of words, but just to make the examples in this video easier for you and me to think about, let's simplify by pretending that tokens are always just words. The first step in a transformer is to associate each token with a high-dimensional vector, what we call its embedding. Now the most important idea I want you to have in mind is how directions in this high-dimensional space of all possible embeddings can correspond with semantic meaning. In the last chapter we saw an example for how direction can correspond to gender, in the sense that adding a certain step in this space can take you from the embedding of a masculine noun to the embedding of the corresponding feminine noun. That's just one example you could imagine how many other directions in this high-dimensional space could correspond to numerous other aspects of a word's meaning. The aim of a transformer is to progressively adjust these embeddings so that they don't merely encode an individual word, but instead they bacon some much much richer contextual meaning. I should say a front that a lot of people find the attention mechanism, this key piece in a transformer, very confusing, so don't worry if it takes some time for things to sink in. I think that before we dive into the computational details and all the matrix multiplications, it's worth thinking about a couple of examples for the kind of behavior that we want attention to enable. Consider the phrases American true, Mal, one mole of carbon dioxide, and take a biopsy of the mole. You and I know that the word mole has different meanings in each one of these, based on the context. But after the first step of a transformer, the one that breaks up the text and associate see each token with a vector, the vector that's associated with mole would be the same in all three of these cases, because this initial token embedding is effectively a look-up table with no reference to the context. It's only in the next step of the transformer that the surrounding embeddings have the chance to pass information into this one. The picture you might have in mind is that there are multiple distinct directions in this embedding space, encoding the multiple distinct meanings of the word mall, and that a well-trained attention block calculates what you need to add to the generic embedding to move it to one of these more specific directions as a function of the context. To take another example, consider the embedding of the word tower. This is presumably some very generic non-specific direction in the space associated with lots of other large tall nouns. If this word was immediately preceded by Eiffel, you could imagine wanting the mechanism to update this vector so that it points in a direction that more specifically encodes the Eiffel Tower, maybe correlated with vectors associated with Paris and France and things made of steel. If it was also preceded by the word miniature, then the vector should be updated even further so that it no longer correlates with large tall things. More generally than just refining the meaning of a word, the attention block allows the model to move information encoded in one embedding to that of another, potentially ones that are quite far away, and potentially with information that's much richer than just a single word. What we saw in the last chapter was how after all of the vectors flow through the network, including many different attention blocks. The computation that you perform to produce a prediction of the next token is entirely a function of the last vector in the sequence. So imagine, for example, that the text you input is most of an entire mystery novel, all the way up to a point near the end, which reads, therefore the murderer was, if the model's going to accurately predict the next word, that final vector in the sequence, which began its life simply embedding the word was, will have to have been updated by all of the attention blocks to represent much more than any individual word, somehow encoding all of the information from the full context window that's relevant to predicting the next word. To step through the computations though, let's take a much simpler example, imagine that the input includes the phrase, a fluffy blue creature roamed the word in forest. And for the moment, suppose that the only type of update that we care about is having the adjectives adjust the meanings of their corresponding nouns. What I'm about to describe is what we would call a single head of attention, and later we will see how the attention block consists of many different heads run in parallel. Again, the initial embedding for each word is some high dimensional vector that only encodes the meaning of that particular word with no context. Actually, that's not quite true. They also encode the meaning of that particular word with no context. Actually, that's not quite true. They also encode the position of the word. There's a lot more to say about the specific way the positions are encoded, but right now, all you need to know is that the entries of this vector are enough to tell you both what the word is and where it exists in the context. Let's go ahead and denote these embeddings with the letter E. The goal is to have a series of computations, produce a new refined set of embeddings, where for example those corresponding to the nouns have ingested the meaning from their corresponding adjectives. And playing the deep learning game, we want most of the computations involved to look like matrix vector products, where the matrices are full of tunable weights, things that the model will learn based on data. To be clear, I'm making up this example of adjectives updating nouns just to illustrate the type of behavior that you could imagine an intention had to do. As with so much deep learning, the true behavior is much harder to parse, because it's based on tweaking and tuning, a huge number of parameters to minimize some cost function. It's just that as we step through all of the different matrices filled with parameters that are involved in this process, I think it's really helpful to have an imagined example of something that it could be doing to help keep it all more concrete. For the first step of this process, you might imagine each noun, like creature, asking the question, hey, are there any adjectives sitting in front of me? And for the words fluffy and blue, to each be able to answer, yeah, I'm an adjective, and I'm in that position. That question is somehow encoded as yet another vector, another list of numbers, which we call the query for this word. This query vector, though, has a much smaller dimension than the embedding vector, say 128. Computing this query looks like taking a certain matrix, which all labeled WQ, and multiplying it by the embedding. Compressing things a bit, let's write that query vector as Q, and then anytime you see me put a matrix next to an arrow like this one, it's meant to represent that multiplying this matrix by the vector at the arrows start, gives you the vector at the arrows end. In this case, you multiply this matrix by the vector at the arrows start, gives you the vector at the arrows end. In this case, you multiply this matrix by all of the embeddings in the context, producing one query vector for each token. The entries of this matrix are parameters of the model, which means the true behavior is learned from data, and in practice what this matrix does in a particular attention head is challenging to parse. But for R-sake, imagining an example that we might hope that it would learn, will suppose that this query matrix maps the embeddings of nouns to certain directions in this smaller query space that somehow encodes the notion of looking for adjectives in preceding positions. As to what it does to other embeddings, who knows? Maybe it simultaneously tries to accomplish some other goal with those, right now, where laser focused on the nouns. At the same time, associated with this is a second matrix called the key matrix, which you also multiply by every one of the embeddings. This produces a second sequence of vectors that we call the keys. Conceptually, you want to think of the keys as potentially answering the queries. This key matrix is also full of tunable parameters, and just like the query matrix, it maps the embedding vectors to that same smaller dimensional space. You think of the keys as matching the queries, whenever they closely align with each other. In our example, you would imagine that the key matrix maps the adjectives, like fluffy and blue, to vectors that are closely aligned with the query produced by the word creature. To measure how well each key matches each query, you compute a dot product between each possible key query pair. I like to visualize a grid full of a bunch of dots where the bigger dots correspond to the larger dot products, the places where the keys and queries align. For our adjective noun example, that would look a little more like this, places where the keys and queries align. For our adjective noun example, that would look a little more like this, where if the keys produced by fluffy and blue really do align closely with the query produced by creature, then the dot products in these two spots would be some large positive numbers. In the lingo machine learning people would say that this means the embeddings of fluffy and blue attend to the embedding of creature. By contrast, the dot product between the key for some other words, like the and the query for creature, would be some small or negative value that reflects that these are unrelated to each other. So we have this grid of values that can be any real number from negative infinity to infinity, giving us a score for how relevant each word is to updating the meaning of every other word. The way we're about to use these scores is to take a certain weighted sum along each column, weighted by the relevance. So instead of having values range from negative infinity to infinity, what we want is for the numbers in these columns to be between 0 and 1, and for each column to add up to 1, as if they were a probability distribution. If you're coming in from the last chapter, you know what we need to do then. We compute a softmax along each one of these columns to normalize the values. In our picture, after you apply softmax to all of the columns, we'll fill in the grid with these normalized values. At this point, you're safe to think about each column as giving weights, according to how relevant the word on the left is to the corresponding value at the top. We call this grid an attention pattern. Now if you look at the original transformer paper, there's a really compact way that they write this all down. Here, the variable's Q and K represent the full arrays of query and key vectors respectively. Those little vectors you get by multiplying the embeddings by the query and the key matrices. This expression up in the numerator is a really compact way to represent the grid of all possible dot products between pairs of keys and queries. A small technical detail that I didn't mention is that for numerical stability, it happens to be helpful to divide all of these values by the square root of the dimension in that key query space. Then this softmax that's wrapped around the full expression is meant to be understood to apply column by column. As to that V term, we'll talk about it in just a second. Before that, there's one other technical detail that so far I've skipped. During the training process, when you run this model on a given text example, and all of the weights are slightly adjusted in tune to either reward or punish it, based on how high a probability it assigns to the true next word in the passage. It turns out to make the whole training process a lot more efficient, if you simultaneously have it predict every possible next token, following each initial sub-sequence of tokens in this passage. For example, with the phrase that we've been focusing on, it might also be predicting what words follow creature and what words follow the. This is really nice because it means what would otherwise be a single training example, effectively acts as many. For the purposes of our attention pattern, it means that you never want to allow later words to influence earlier words, since otherwise they could kind of give away the answer for what comes next. What this means is that we want all of these spots here, the ones representing later tokens, influencing earlier ones, to somehow be forced to be zero. The simplest thing you might think to do is to set the meacul to zero, but if you did that, the columns wouldn't add up to one anymore, they wouldn't be normalized. So instead, a common way to do this is that before applying softbacks, you set all of those entries to be negative infinity. If you do that, then after applying softmax, all of those get turned into zero, but the columns stay normalized. This process is called masking. There are versions of attention where you don't apply it, but in our GPT example, even though this is more relevant during the training phase than it would be, say, running it as a chat bot or something like that, you do always apply this masking to prevent later tokens from influencing earlier ones. Another fact that's worth reflecting on about this attention pattern is how its size is equal to the square of the context size. So this is why context size can be a really huge bottleneck for large language models, and scaling it up is non-trivial. As you might imagine, motivated by a desire for bigger and bigger context windows, recent years have seen some variations to the attention mechanism aimed at making context more scalable, but right here, you and I are staying focused on the basics. Okay, great, computing this pattern lets the model deduce which words are relevant to which other words. Now you need to actually update the embeddings, allowing words to pass information to whichever other words they're relevant to. For example, you want the embedding of fluffy to somehow cause a change to creature that moves it to a different part of this 12,000 dimensional embedding space that more specifically encodes a fluffy creature. What I'm going to do here is first show you the most straightforward way that you could do this, though there's a slight way that this gets modified in the context of multi-headed attention. This most straightforward way would be to use a third matrix, what we call the value matrix, which you multiply by the embedding of that first word, for example, Fluffy. The result of this is what you would call a value vector, and this is something that you add to the embedding of the second word, in this case something you add to the embedding of creature. So this value vector lives in the same very high dimensional space as the embeddings. When you multiply this value matrix by the embedding of a word, you might think of it as saying if this word is relevant to adjusting the meaning of something else, what exactly should be added to the embedding of that something else in order to reflect this? Looking back in our diagram, let's set aside all of the keys and the queries, since after you compute the attention pattern you're done with those, then you're going to take this value matrix and multiply it by every one of those embeddings to produce a sequence of value vectors. You might think of these value vectors as being kind of associated with the corresponding keys. For each column in this diagram, you multiply each of the value vectors by the corresponding weight in that column. For example, here, under the embedding of creature, you would be adding large proportions of the value vectors for fluffy and blue, while all of the other value vectors get zeroed out, or at least nearly zeroed out. And then finally, the weight to actually update the embedding associated with this column, previously encoding some context-free meaning of creature, you add together all of these re-scaled values in the column, producing a change that you want to add that all labeled Delta E, and then you add that to the original embedding. Hopefully, what results is a more refined vector encoding the more context-ruly-rich meaning, like that of a fluffy blue creature. And of course, you don't just do this to one embedding, you apply the same weighted sum across all of the columns in this picture, producing a sequence of changes. Adding all of those changes to the corresponding embeddings produces a full sequence of more refined embeddings popping out of the attention block. Zooming out, this whole process is what you would describe as a single head of attention. As I've described things so far, this process is parametrized by three distinct matrices, all filled with tunable parameters, the key, the query, and the value. I want to take a moment to continue what we started in the last chapter with the score keeping where we count up the total number of model parameters using the numbers from GPT3. These key inquiry matrices each have 12,288 columns matching the embedding dimension and 128 rows matching the dimension of that smaller key query space. This gives us an additional 1.5 million or so parameters for each one. If you look at that value matrix by contrast, the way I've described things so far would suggest that it's a square matrix that has 12,200,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8 about 150 million added parameters. And to be clear, you could do that. You could devote orders of magnitude more parameters to the value map than to the key in query. But in practice, it is much more efficient if instead you make it so that the number of parameters devoted to this value map is the same as the number devoted to the key in the query. This is especially relevant in the setting of running multiple attention heads in parallel. The way this looks is that the value map is factored as a product of two smaller matrices. Conceptually, I would still encourage you to think about the overall linear map, one with inputs and outputs, both in this larger embedding space, for example taking the embedding of blue to this blueness direction that you would add to nouns. It's just that it's broken up into two separate steps. The first matrix on the right here has a smaller number of rows, typically the same size as the key query space, what this means is you can think of it as mapping the large embedding vectors down to a much smaller space. This is not the conventional naming, but I'm going to call this the value down matrix. The second matrix maps from the smaller space back up to the embedding space, producing the vectors that you use to make the actual updates. I'm going to call this one the value up matrix, which, again, is not conventional. The way that you would see this written in most papers looks a little different. I'll talk about it in a minute, in my opinion, it tends to make things a little more conceptually confusing. To throw in linear algebra jargon here, what we're basically doing is constraining the overall value map to be a low-rank transformation. Turning back to the parameter count, all four of these matrices have the same size, and adding them all up, we get about 6.3 million parameters for one attention head. As a quick side note, to be a little more accurate, everything described so far is what people would call a self-attention head, to distinguish it from a variation that comes up in other models that's called cross-attention. This isn't relevant to our GPT example, but if you're curious, cross-attention involves models that process two distinct types of data, like text in one language and text in another language that's part of an ongoing generation of a translation, or maybe audio input of speech and an ongoing transcription. A cross-attention head looks almost identical. The only difference is that the key and query maps act on different datasets. In a model-doing translation, for example, the keys might come from one language, while the queries come from another, and the attention pattern, could describe which words from one language correspond to which words in another. And in this setting, there would typically be no masking, since there's not really any notion of later tokens affecting earlier ones. Staying focused on self-attention, though, if you understood everything so far, and if you were to stop here, you would come away with the essence of what attention really is. All that's really left to us is to lay out the sense in which you do this many many different times. In our central example, we focused on adjectives updating nouns, but of course there were lots of different ways that context can influence the meaning of a word. If the words, they crashed the, preceded the word, car, it has implications for the shape and the structure of that car. And a lot of associations might be less grammatical. If the word wizard is anywhere in the same passage as Harry, it suggests that this might be referring to Harry Potter. Whereas if instead, the words queen, Sussex, and William were in that passage, then perhaps the embedding of Harry should instead be updated to refer to the prints. For every different type of contextual updating that you might imagine, the parameters of these key inquiry matrices would be different to capture the different attention patterns, and the parameters of our value map would be different based on what should be added to the embeddings. And again, in practice, the true behavior of these maps is much more difficult to interpret, where the weights are set to do whatever the model needs them to do to best accomplish its goal of predicting the next token. As I said before, everything were described as a single head of attention, and a full attention block inside a transformer consists of what's called multi-headed attention, where you run a lot of these operations in parallel, each with its own distinct key query and value maps. GPT-3, for example, uses 96 attention heads inside each block. Considering that each one is already a bit confusing, it's certainly a lot to hold in your head. Just to spell it all out very explicitly, this means you have 96 distinct key and query matrices, producing 96 distinct attention patterns. Then each head has its own distinct value matrices, used to produce 96 sequences of value vectors. These are all added together using the corresponding attention patterns as weights. What this means is that for each position in the context, each token, every one of these heads produces a proposed change to be added to the embedding in that position. So what you do is you sum together all of those proposed changes, one for each head, and you add the result to the original embedding of that position. This entire sum here would be one slice of what's outputted from this multi-headed attention block, a single one of those refined embeddings that pops out the other end of it. Again, this is a lot to think about, so don't worry at all if it takes some time to sink in. The overall idea is that by running many distinct heads in parallel, you're giving the model the capacity to learn many distinct ways that context changes meaning. Pulling up our running tally for parameter count, with 96 heads, each including its own variation of these four matrices, each block of multi-headed attention ends up with around 600 million parameters. There's one added slightly annoying thing that I should really mention for any of you who go on to read more about transformers. You remember how I said that the value map is factored out into these two distinct matrices, which I labeled as the value down and the value up matrices. The way that I framed things would suggest that you see this pair of matrices inside each attention head, and you could absolutely implement it this way, that would be a valid design. But the way that you see this written in papers and the way that it's implemented in practice looks a little different. All of these value up matrices for each head appear stapled together in one giant matrix that we call the output matrix, associated with the entire multi-headed attention block. And when you see people refer to the value matrix for a given attention head, they're typically only referring to this first step, the one that I was labeling as the value down, projection into the smaller space. For the curious among you, I've left an on-screen note about it. It's one of those details that runs the risk of distracting from the main conceptual points, but I do want to call it out just so that you know if you read about this in other sources. Setting aside all the technical nuances in the preview from the last chapter, we saw how data flowing through a transformer doesn't just flow through a single attention block. For one thing, it also goes through these other operations called multilayer perceptrons, we'll talk more about those in the next chapter, and then it repeatedly goes through many many copies of both of these operations. What this means is that after a given word imbibes some of its context, there are many more chances for this more nuanced embedding to be influenced by its more nuanced surroundings. The further down the network you go, with each embedding, taking in more and more meaning from all the other embeddings, which themselves are getting more and more nuanced, the hope is that there's the capacity to encode higher level and more abstract ideas about a given input beyond just descriptors and grammatical structure. Things like sentiment and tone and whether it's a poem and what underlying scientific truths are relevant to the piece and things like that. Turning back one more time to our scorekeeping, GPT-3 includes 96 distinct layers, so the total number of key query and value parameters is multiplied by another 96, which brings the total sum to just under 58 billion distinct parameters devoted to all of the attention heads. That is a lot to be sure, but it's only about a third of the 175 billion that are in the network in total. So even though attention gets all of the attention, the majority of parameters come from the blocks sitting in between these steps. In the next chapter, you and I will talk more about those other blocks and also a lot more about the training process. A big part of the story for the success of the attention mechanism is not so much any specific kind of behavior that enables, but the fact that it's extremely parallelizable, meaning that you can run a huge number of computations in a short time using GPUs. Given that one of the big lessons about deep learning in the last decade or two has been that scale alone seems to give huge qualitative improvements in model performance, there's a huge advantage to parallelizable architectures that let you do this. If you want to learn more about this stuff, I've left lots of links in the description. In particular, anything produced by Andre Carpathia, Chris Ola, tend to be pure gold. In this video, I wanted to just jump into attention in its current form, but if you're curious about more of the history for how we got here and how you might reinvent this idea for yourself, my friend Vivek just put up a couple videos, giving a lot more of that motivation. Also, Britt Cruz from the channel The art of the problem has a really nice video about the history of large language models. you\",\n",
       " 'chunks': [{'timestamp': (0.0, 4.4),\n",
       "   'text': ' In the last chapter, you and I started to step through the internal workings of a transformer.'},\n",
       "  {'timestamp': (4.4, 7.84),\n",
       "   'text': ' This is one of the key pieces of technology inside large language models,'},\n",
       "  {'timestamp': (7.84, 10.8),\n",
       "   'text': ' and a lot of other tools in the modern way of AI.'},\n",
       "  {'timestamp': (10.8, 15.52),\n",
       "   'text': ' It first hit the scene and a now-famous 2017 paper called Attention as All You Need,'},\n",
       "  {'timestamp': (15.52, 19.68),\n",
       "   'text': ' and in this chapter, you and I will dig into what this attention mechanism is,'},\n",
       "  {'timestamp': (19.68, 21.6), 'text': ' visualizing how it processes data.'},\n",
       "  {'timestamp': (26.48, 30.12),\n",
       "   'text': \" As a quick recap, here's the important context I want you to have in mind.\"},\n",
       "  {'timestamp': (30.12, 34.72),\n",
       "   'text': ' The goal of the model that you and I are studying is to take in a piece of text and predict'},\n",
       "  {'timestamp': (34.72, 36.8), 'text': ' what word comes next.'},\n",
       "  {'timestamp': (36.8, 41.04),\n",
       "   'text': ' The input text is broken up into little pieces that we call tokens, and these are very'},\n",
       "  {'timestamp': (41.04, 47.0),\n",
       "   'text': ' often words or pieces of words, but just to make the examples in this video easier for you and me to think about,'},\n",
       "  {'timestamp': (47.0, 51.0),\n",
       "   'text': \" let's simplify by pretending that tokens are always just words.\"},\n",
       "  {'timestamp': (51.0, 58.0),\n",
       "   'text': ' The first step in a transformer is to associate each token with a high-dimensional vector, what we call its embedding.'},\n",
       "  {'timestamp': (58.0, 65.8),\n",
       "   'text': ' Now the most important idea I want you to have in mind is how directions in this high-dimensional space of all possible embeddings can correspond'},\n",
       "  {'timestamp': (65.8, 70.6),\n",
       "   'text': ' with semantic meaning. In the last chapter we saw an example for how direction can correspond'},\n",
       "  {'timestamp': (70.6, 75.8),\n",
       "   'text': ' to gender, in the sense that adding a certain step in this space can take you from the embedding'},\n",
       "  {'timestamp': (75.8, 80.52),\n",
       "   'text': \" of a masculine noun to the embedding of the corresponding feminine noun. That's just one\"},\n",
       "  {'timestamp': (80.52, 84.72),\n",
       "   'text': ' example you could imagine how many other directions in this high-dimensional space could'},\n",
       "  {'timestamp': (84.72, 87.56),\n",
       "   'text': \" correspond to numerous other aspects of a word's meaning.\"},\n",
       "  {'timestamp': (88.56, 95.52),\n",
       "   'text': \" The aim of a transformer is to progressively adjust these embeddings so that they don't merely encode an individual word,\"},\n",
       "  {'timestamp': (95.52, 99.2),\n",
       "   'text': ' but instead they bacon some much much richer contextual meaning.'},\n",
       "  {'timestamp': (99.92, 108.64),\n",
       "   'text': \" I should say a front that a lot of people find the attention mechanism, this key piece in a transformer, very confusing, so don't worry if it takes some time for things to sink in.\"},\n",
       "  {'timestamp': (109.36, 113.76),\n",
       "   'text': ' I think that before we dive into the computational details and all the matrix multiplications,'},\n",
       "  {'timestamp': (113.76, 118.24),\n",
       "   'text': \" it's worth thinking about a couple of examples for the kind of behavior that we want attention\"},\n",
       "  {'timestamp': (118.24, 126.68),\n",
       "   'text': ' to enable. Consider the phrases American true, Mal, one mole of carbon dioxide, and take a biopsy of the mole.'},\n",
       "  {'timestamp': (126.68, 131.4),\n",
       "   'text': ' You and I know that the word mole has different meanings in each one of these, based on the context.'},\n",
       "  {'timestamp': (131.4, 135.04),\n",
       "   'text': ' But after the first step of a transformer, the one that breaks up the text and associate'},\n",
       "  {'timestamp': (135.04, 141.4),\n",
       "   'text': \" see each token with a vector, the vector that's associated with mole would be the same in all three of these cases,\"},\n",
       "  {'timestamp': (141.4, 150.16),\n",
       "   'text': \" because this initial token embedding is effectively a look-up table with no reference to the context. It's only in the next step of the transformer that the surrounding\"},\n",
       "  {'timestamp': (150.16, 154.56),\n",
       "   'text': ' embeddings have the chance to pass information into this one. The picture you might have'},\n",
       "  {'timestamp': (154.56, 158.24),\n",
       "   'text': ' in mind is that there are multiple distinct directions in this embedding space,'},\n",
       "  {'timestamp': (158.24, 162.8),\n",
       "   'text': ' encoding the multiple distinct meanings of the word mall, and that a well-trained attention'},\n",
       "  {'timestamp': (162.8, 165.28),\n",
       "   'text': ' block calculates what you need to add'},\n",
       "  {'timestamp': (165.28, 171.6),\n",
       "   'text': ' to the generic embedding to move it to one of these more specific directions as a function of the context.'},\n",
       "  {'timestamp': (172.96, 177.6),\n",
       "   'text': ' To take another example, consider the embedding of the word tower. This is presumably'},\n",
       "  {'timestamp': (177.6, 182.88),\n",
       "   'text': ' some very generic non-specific direction in the space associated with lots of other large tall'},\n",
       "  {'timestamp': (182.88, 188.64),\n",
       "   'text': ' nouns. If this word was immediately preceded by Eiffel, you could imagine wanting the mechanism'},\n",
       "  {'timestamp': (188.64, 193.36),\n",
       "   'text': ' to update this vector so that it points in a direction that more specifically encodes'},\n",
       "  {'timestamp': (193.36, 198.28),\n",
       "   'text': ' the Eiffel Tower, maybe correlated with vectors associated with Paris and France and things'},\n",
       "  {'timestamp': (198.28, 199.92), 'text': ' made of steel.'},\n",
       "  {'timestamp': (199.92, 204.72),\n",
       "   'text': ' If it was also preceded by the word miniature, then the vector should be updated even further'},\n",
       "  {'timestamp': (204.72, 209.62),\n",
       "   'text': ' so that it no longer correlates with large tall things.'},\n",
       "  {'timestamp': (209.62, 213.78),\n",
       "   'text': ' More generally than just refining the meaning of a word, the attention block allows the model'},\n",
       "  {'timestamp': (213.78, 218.74),\n",
       "   'text': ' to move information encoded in one embedding to that of another, potentially ones that'},\n",
       "  {'timestamp': (218.74, 222.82),\n",
       "   'text': \" are quite far away, and potentially with information that's much richer than just a single\"},\n",
       "  {'timestamp': (222.82, 224.02), 'text': ' word.'},\n",
       "  {'timestamp': (224.02, 228.0),\n",
       "   'text': ' What we saw in the last chapter was how after all of the vectors flow through the network,'},\n",
       "  {'timestamp': (228.0, 230.0),\n",
       "   'text': ' including many different attention blocks.'},\n",
       "  {'timestamp': (230.0, 236.4),\n",
       "   'text': ' The computation that you perform to produce a prediction of the next token is entirely a function'},\n",
       "  {'timestamp': (236.4, 239.0),\n",
       "   'text': ' of the last vector in the sequence.'},\n",
       "  {'timestamp': (239.0, 243.6),\n",
       "   'text': ' So imagine, for example, that the text you input is most of an entire mystery novel,'},\n",
       "  {'timestamp': (243.6, 245.4),\n",
       "   'text': ' all the way up to a point near the end,'},\n",
       "  {'timestamp': (245.4, 248.48),\n",
       "   'text': ' which reads, therefore the murderer was,'},\n",
       "  {'timestamp': (248.48, 251.28),\n",
       "   'text': \" if the model's going to accurately predict the next word,\"},\n",
       "  {'timestamp': (251.28, 253.04),\n",
       "   'text': ' that final vector in the sequence,'},\n",
       "  {'timestamp': (253.04, 256.32),\n",
       "   'text': ' which began its life simply embedding the word was,'},\n",
       "  {'timestamp': (256.32, 259.24),\n",
       "   'text': ' will have to have been updated by all of the attention blocks'},\n",
       "  {'timestamp': (259.24, 262.4),\n",
       "   'text': ' to represent much more than any individual word,'},\n",
       "  {'timestamp': (262.4, 264.56),\n",
       "   'text': ' somehow encoding all of the information'},\n",
       "  {'timestamp': (264.56, 266.88),\n",
       "   'text': \" from the full context window that's relevant\"},\n",
       "  {'timestamp': (266.88, 268.4), 'text': ' to predicting the next word.'},\n",
       "  {'timestamp': (269.48, 270.96),\n",
       "   'text': ' To step through the computations though,'},\n",
       "  {'timestamp': (270.96, 272.92),\n",
       "   'text': \" let's take a much simpler example,\"},\n",
       "  {'timestamp': (272.92, 275.24),\n",
       "   'text': ' imagine that the input includes the phrase,'},\n",
       "  {'timestamp': (275.24, 278.48),\n",
       "   'text': ' a fluffy blue creature roamed the word in forest.'},\n",
       "  {'timestamp': (278.48, 279.36), 'text': ' And for the moment,'},\n",
       "  {'timestamp': (279.36, 282.32),\n",
       "   'text': ' suppose that the only type of update that we care about'},\n",
       "  {'timestamp': (282.32, 284.88),\n",
       "   'text': ' is having the adjectives adjust the meanings'},\n",
       "  {'timestamp': (284.88, 286.96), 'text': ' of their corresponding nouns.'},\n",
       "  {'timestamp': (286.96, 291.52),\n",
       "   'text': \" What I'm about to describe is what we would call a single head of attention, and later\"},\n",
       "  {'timestamp': (291.52, 296.12),\n",
       "   'text': ' we will see how the attention block consists of many different heads run in parallel.'},\n",
       "  {'timestamp': (296.12, 300.56),\n",
       "   'text': ' Again, the initial embedding for each word is some high dimensional vector that only encodes'},\n",
       "  {'timestamp': (300.56, 303.96),\n",
       "   'text': ' the meaning of that particular word with no context.'},\n",
       "  {'timestamp': (303.96, 305.5),\n",
       "   'text': \" Actually, that's not quite true. They also encode the meaning of that particular word with no context. Actually, that's not quite true.\"},\n",
       "  {'timestamp': (305.5, 308.0),\n",
       "   'text': ' They also encode the position of the word.'},\n",
       "  {'timestamp': (308.0, 311.84),\n",
       "   'text': \" There's a lot more to say about the specific way the positions are encoded, but right\"},\n",
       "  {'timestamp': (311.84, 316.04),\n",
       "   'text': ' now, all you need to know is that the entries of this vector are enough to tell you both what'},\n",
       "  {'timestamp': (316.04, 319.44),\n",
       "   'text': ' the word is and where it exists in the context.'},\n",
       "  {'timestamp': (319.44, 322.4),\n",
       "   'text': \" Let's go ahead and denote these embeddings with the letter E.\"},\n",
       "  {'timestamp': (322.4, 329.76),\n",
       "   'text': ' The goal is to have a series of computations, produce a new refined set of embeddings, where for example those corresponding to the nouns'},\n",
       "  {'timestamp': (329.76, 334.88),\n",
       "   'text': ' have ingested the meaning from their corresponding adjectives. And playing the deep learning'},\n",
       "  {'timestamp': (334.88, 339.52),\n",
       "   'text': ' game, we want most of the computations involved to look like matrix vector products, where'},\n",
       "  {'timestamp': (339.52, 343.76),\n",
       "   'text': ' the matrices are full of tunable weights, things that the model will learn based on data.'},\n",
       "  {'timestamp': (344.48, 348.92),\n",
       "   'text': \" To be clear, I'm making up this example of adjectives updating nouns just to illustrate\"},\n",
       "  {'timestamp': (348.92, 352.96),\n",
       "   'text': ' the type of behavior that you could imagine an intention had to do.'},\n",
       "  {'timestamp': (352.96, 356.6),\n",
       "   'text': \" As with so much deep learning, the true behavior is much harder to parse, because it's\"},\n",
       "  {'timestamp': (356.6, 361.96),\n",
       "   'text': ' based on tweaking and tuning, a huge number of parameters to minimize some cost function.'},\n",
       "  {'timestamp': (361.96, 368.72),\n",
       "   'text': \" It's just that as we step through all of the different matrices filled with parameters that are involved in this process, I think it's really helpful to have\"},\n",
       "  {'timestamp': (368.72, 373.12),\n",
       "   'text': ' an imagined example of something that it could be doing to help keep it all more concrete.'},\n",
       "  {'timestamp': (373.92, 377.92),\n",
       "   'text': ' For the first step of this process, you might imagine each noun, like creature,'},\n",
       "  {'timestamp': (377.92, 382.88),\n",
       "   'text': ' asking the question, hey, are there any adjectives sitting in front of me? And for the words'},\n",
       "  {'timestamp': (382.88, 387.04),\n",
       "   'text': \" fluffy and blue, to each be able to answer, yeah, I'm an adjective,\"},\n",
       "  {'timestamp': (387.04, 388.24), 'text': \" and I'm in that position.\"},\n",
       "  {'timestamp': (389.32, 392.52),\n",
       "   'text': ' That question is somehow encoded as yet another vector,'},\n",
       "  {'timestamp': (392.52, 396.8),\n",
       "   'text': ' another list of numbers, which we call the query for this word.'},\n",
       "  {'timestamp': (396.8, 398.04), 'text': ' This query vector, though,'},\n",
       "  {'timestamp': (398.04, 400.84),\n",
       "   'text': ' has a much smaller dimension than the embedding vector,'},\n",
       "  {'timestamp': (400.84, 402.84), 'text': ' say 128.'},\n",
       "  {'timestamp': (402.84, 406.18),\n",
       "   'text': ' Computing this query looks like taking a certain matrix, which all labeled'},\n",
       "  {'timestamp': (406.18, 412.48),\n",
       "   'text': \" WQ, and multiplying it by the embedding. Compressing things a bit, let's write that\"},\n",
       "  {'timestamp': (412.48, 417.82),\n",
       "   'text': ' query vector as Q, and then anytime you see me put a matrix next to an arrow like this'},\n",
       "  {'timestamp': (417.82, 422.24),\n",
       "   'text': \" one, it's meant to represent that multiplying this matrix by the vector at the arrows\"},\n",
       "  {'timestamp': (422.24, 426.0),\n",
       "   'text': ' start, gives you the vector at the arrows end. In this case, you multiply this matrix by the vector at the arrows start, gives you the vector at the arrows end.'},\n",
       "  {'timestamp': (430.0, 436.32),\n",
       "   'text': ' In this case, you multiply this matrix by all of the embeddings in the context, producing one query vector for each token. The entries of this matrix are parameters of the model,'},\n",
       "  {'timestamp': (436.32, 440.8),\n",
       "   'text': ' which means the true behavior is learned from data, and in practice what this matrix does in a'},\n",
       "  {'timestamp': (440.8, 447.94),\n",
       "   'text': ' particular attention head is challenging to parse. But for R-sake, imagining an example that we might hope that it would learn, will suppose'},\n",
       "  {'timestamp': (447.94, 452.6),\n",
       "   'text': ' that this query matrix maps the embeddings of nouns to certain directions in this smaller'},\n",
       "  {'timestamp': (452.6, 458.92),\n",
       "   'text': ' query space that somehow encodes the notion of looking for adjectives in preceding positions.'},\n",
       "  {'timestamp': (458.92, 461.72),\n",
       "   'text': ' As to what it does to other embeddings, who knows?'},\n",
       "  {'timestamp': (461.72, 467.32),\n",
       "   'text': ' Maybe it simultaneously tries to accomplish some other goal with those, right now, where laser focused on the nouns.'},\n",
       "  {'timestamp': (467.32, 472.2),\n",
       "   'text': ' At the same time, associated with this is a second matrix called the key matrix, which'},\n",
       "  {'timestamp': (472.2, 475.28),\n",
       "   'text': ' you also multiply by every one of the embeddings.'},\n",
       "  {'timestamp': (475.28, 479.36),\n",
       "   'text': ' This produces a second sequence of vectors that we call the keys.'},\n",
       "  {'timestamp': (479.36, 483.96),\n",
       "   'text': ' Conceptually, you want to think of the keys as potentially answering the queries.'},\n",
       "  {'timestamp': (483.96, 489.52),\n",
       "   'text': ' This key matrix is also full of tunable parameters, and just like the query matrix, it maps the embedding vectors to that'},\n",
       "  {'timestamp': (489.52, 495.2),\n",
       "   'text': ' same smaller dimensional space. You think of the keys as matching the queries, whenever they'},\n",
       "  {'timestamp': (495.2, 500.08),\n",
       "   'text': ' closely align with each other. In our example, you would imagine that the key matrix maps the'},\n",
       "  {'timestamp': (500.08, 505.28),\n",
       "   'text': ' adjectives, like fluffy and blue, to vectors that are closely aligned with the query'},\n",
       "  {'timestamp': (505.28, 507.6), 'text': ' produced by the word creature.'},\n",
       "  {'timestamp': (507.6, 512.44),\n",
       "   'text': ' To measure how well each key matches each query, you compute a dot product between each'},\n",
       "  {'timestamp': (512.44, 514.88), 'text': ' possible key query pair.'},\n",
       "  {'timestamp': (514.88, 519.2),\n",
       "   'text': ' I like to visualize a grid full of a bunch of dots where the bigger dots correspond to'},\n",
       "  {'timestamp': (519.2, 523.4),\n",
       "   'text': ' the larger dot products, the places where the keys and queries align.'},\n",
       "  {'timestamp': (523.4, 525.12),\n",
       "   'text': ' For our adjective noun example, that would look a little more like this, places where the keys and queries align. For our adjective noun example,'},\n",
       "  {'timestamp': (525.12, 530.4),\n",
       "   'text': ' that would look a little more like this, where if the keys produced by fluffy and blue'},\n",
       "  {'timestamp': (530.4, 535.6),\n",
       "   'text': ' really do align closely with the query produced by creature, then the dot products in these two'},\n",
       "  {'timestamp': (535.6, 541.04),\n",
       "   'text': ' spots would be some large positive numbers. In the lingo machine learning people would say that'},\n",
       "  {'timestamp': (541.04, 550.24),\n",
       "   'text': ' this means the embeddings of fluffy and blue attend to the embedding of creature. By contrast, the dot product between the key for some other words, like the'},\n",
       "  {'timestamp': (550.24, 555.28),\n",
       "   'text': ' and the query for creature, would be some small or negative value that reflects that these are'},\n",
       "  {'timestamp': (555.28, 561.44),\n",
       "   'text': ' unrelated to each other. So we have this grid of values that can be any real number from negative'},\n",
       "  {'timestamp': (561.44, 565.28),\n",
       "   'text': ' infinity to infinity, giving us a score for how relevant'},\n",
       "  {'timestamp': (565.28, 569.16),\n",
       "   'text': ' each word is to updating the meaning of every other word.'},\n",
       "  {'timestamp': (569.16, 573.48),\n",
       "   'text': \" The way we're about to use these scores is to take a certain weighted sum along each\"},\n",
       "  {'timestamp': (573.48, 576.48),\n",
       "   'text': ' column, weighted by the relevance.'},\n",
       "  {'timestamp': (576.48, 580.96),\n",
       "   'text': ' So instead of having values range from negative infinity to infinity, what we want is for'},\n",
       "  {'timestamp': (580.96, 589.28),\n",
       "   'text': ' the numbers in these columns to be between 0 and 1, and for each column to add up to 1, as if they were a probability distribution.'},\n",
       "  {'timestamp': (589.28, 592.6),\n",
       "   'text': \" If you're coming in from the last chapter, you know what we need to do then.\"},\n",
       "  {'timestamp': (592.6, 600.36),\n",
       "   'text': ' We compute a softmax along each one of these columns to normalize the values.'},\n",
       "  {'timestamp': (600.36, 604.32),\n",
       "   'text': \" In our picture, after you apply softmax to all of the columns, we'll fill in the grid\"},\n",
       "  {'timestamp': (604.32, 606.0), 'text': ' with these normalized values.'},\n",
       "  {'timestamp': (606.0, 615.0),\n",
       "   'text': \" At this point, you're safe to think about each column as giving weights, according to how relevant the word on the left is to the corresponding value at the top.\"},\n",
       "  {'timestamp': (615.0, 618.0),\n",
       "   'text': ' We call this grid an attention pattern.'},\n",
       "  {'timestamp': (618.0, 629.76),\n",
       "   'text': \" Now if you look at the original transformer paper, there's a really compact way that they write this all down. Here, the variable's Q and K represent the full arrays of query and key vectors\"},\n",
       "  {'timestamp': (629.76, 633.84),\n",
       "   'text': ' respectively. Those little vectors you get by multiplying the embeddings by the query and the'},\n",
       "  {'timestamp': (633.84, 639.36),\n",
       "   'text': ' key matrices. This expression up in the numerator is a really compact way to represent the grid'},\n",
       "  {'timestamp': (639.36, 648.28),\n",
       "   'text': \" of all possible dot products between pairs of keys and queries. A small technical detail that I didn't mention is that for numerical stability, it happens\"},\n",
       "  {'timestamp': (648.28, 652.9),\n",
       "   'text': ' to be helpful to divide all of these values by the square root of the dimension in that'},\n",
       "  {'timestamp': (652.9, 654.82), 'text': ' key query space.'},\n",
       "  {'timestamp': (654.82, 659.2),\n",
       "   'text': \" Then this softmax that's wrapped around the full expression is meant to be understood to\"},\n",
       "  {'timestamp': (659.2, 661.76), 'text': ' apply column by column.'},\n",
       "  {'timestamp': (661.76, 665.76),\n",
       "   'text': \" As to that V term, we'll talk about it in just a second. Before that, there's\"},\n",
       "  {'timestamp': (665.76, 670.56),\n",
       "   'text': \" one other technical detail that so far I've skipped. During the training process, when you run\"},\n",
       "  {'timestamp': (670.56, 675.12),\n",
       "   'text': ' this model on a given text example, and all of the weights are slightly adjusted in tune'},\n",
       "  {'timestamp': (675.12, 679.6),\n",
       "   'text': ' to either reward or punish it, based on how high a probability it assigns to the true next'},\n",
       "  {'timestamp': (679.6, 683.76),\n",
       "   'text': ' word in the passage. It turns out to make the whole training process a lot more efficient,'},\n",
       "  {'timestamp': (683.76, 685.04), 'text': ' if you simultaneously'},\n",
       "  {'timestamp': (685.04, 690.88),\n",
       "   'text': ' have it predict every possible next token, following each initial sub-sequence of tokens in this'},\n",
       "  {'timestamp': (690.88, 695.68),\n",
       "   'text': \" passage. For example, with the phrase that we've been focusing on, it might also be predicting\"},\n",
       "  {'timestamp': (695.68, 701.68),\n",
       "   'text': ' what words follow creature and what words follow the. This is really nice because it means what'},\n",
       "  {'timestamp': (701.68, 705.84),\n",
       "   'text': ' would otherwise be a single training example, effectively acts as many.'},\n",
       "  {'timestamp': (705.84, 712.56),\n",
       "   'text': ' For the purposes of our attention pattern, it means that you never want to allow later words to influence earlier words,'},\n",
       "  {'timestamp': (712.56, 716.24),\n",
       "   'text': ' since otherwise they could kind of give away the answer for what comes next.'},\n",
       "  {'timestamp': (716.24, 722.56),\n",
       "   'text': ' What this means is that we want all of these spots here, the ones representing later tokens, influencing earlier ones,'},\n",
       "  {'timestamp': (722.56, 724.56), 'text': ' to somehow be forced to be zero.'},\n",
       "  {'timestamp': (725.92, 729.32),\n",
       "   'text': ' The simplest thing you might think to do is to set the meacul to zero, but if you did'},\n",
       "  {'timestamp': (729.32, 733.08),\n",
       "   'text': \" that, the columns wouldn't add up to one anymore, they wouldn't be normalized.\"},\n",
       "  {'timestamp': (733.08, 737.28),\n",
       "   'text': ' So instead, a common way to do this is that before applying softbacks, you set all of'},\n",
       "  {'timestamp': (737.28, 739.68),\n",
       "   'text': ' those entries to be negative infinity.'},\n",
       "  {'timestamp': (739.68, 743.92),\n",
       "   'text': ' If you do that, then after applying softmax, all of those get turned into zero, but the'},\n",
       "  {'timestamp': (743.92, 746.12), 'text': ' columns stay normalized.'},\n",
       "  {'timestamp': (746.12, 747.84), 'text': ' This process is called masking.'},\n",
       "  {'timestamp': (747.84, 752.08),\n",
       "   'text': \" There are versions of attention where you don't apply it, but in our GPT example, even though\"},\n",
       "  {'timestamp': (752.08, 755.92),\n",
       "   'text': ' this is more relevant during the training phase than it would be, say, running it as a chat'},\n",
       "  {'timestamp': (755.92, 759.76),\n",
       "   'text': ' bot or something like that, you do always apply this masking to prevent later tokens'},\n",
       "  {'timestamp': (759.76, 762.52), 'text': ' from influencing earlier ones.'},\n",
       "  {'timestamp': (762.52, 766.92),\n",
       "   'text': \" Another fact that's worth reflecting on about this attention pattern is how its size\"},\n",
       "  {'timestamp': (766.92, 769.88),\n",
       "   'text': ' is equal to the square of the context size.'},\n",
       "  {'timestamp': (769.88, 774.04),\n",
       "   'text': ' So this is why context size can be a really huge bottleneck for large language models,'},\n",
       "  {'timestamp': (774.04, 776.4), 'text': ' and scaling it up is non-trivial.'},\n",
       "  {'timestamp': (776.4, 780.72),\n",
       "   'text': ' As you might imagine, motivated by a desire for bigger and bigger context windows, recent'},\n",
       "  {'timestamp': (780.72, 789.18),\n",
       "   'text': ' years have seen some variations to the attention mechanism aimed at making context more scalable, but right here, you and I are staying focused on the basics.'},\n",
       "  {'timestamp': (789.18, 794.66),\n",
       "   'text': ' Okay, great, computing this pattern lets the model deduce which words are relevant to'},\n",
       "  {'timestamp': (794.66, 796.06), 'text': ' which other words.'},\n",
       "  {'timestamp': (796.06, 800.96),\n",
       "   'text': ' Now you need to actually update the embeddings, allowing words to pass information to whichever'},\n",
       "  {'timestamp': (800.96, 803.08), 'text': \" other words they're relevant to.\"},\n",
       "  {'timestamp': (803.08, 808.0),\n",
       "   'text': ' For example, you want the embedding of fluffy to somehow cause a change to creature'},\n",
       "  {'timestamp': (808.0, 812.44),\n",
       "   'text': ' that moves it to a different part of this 12,000 dimensional embedding space that more'},\n",
       "  {'timestamp': (812.44, 815.44),\n",
       "   'text': ' specifically encodes a fluffy creature.'},\n",
       "  {'timestamp': (815.44, 818.72),\n",
       "   'text': \" What I'm going to do here is first show you the most straightforward way that you could\"},\n",
       "  {'timestamp': (818.72, 822.88),\n",
       "   'text': \" do this, though there's a slight way that this gets modified in the context of multi-headed\"},\n",
       "  {'timestamp': (822.88, 824.16), 'text': ' attention.'},\n",
       "  {'timestamp': (824.16, 829.12),\n",
       "   'text': ' This most straightforward way would be to use a third matrix, what we call the value matrix,'},\n",
       "  {'timestamp': (829.12, 833.4),\n",
       "   'text': ' which you multiply by the embedding of that first word, for example, Fluffy.'},\n",
       "  {'timestamp': (833.4, 837.44),\n",
       "   'text': ' The result of this is what you would call a value vector, and this is something that you'},\n",
       "  {'timestamp': (837.44, 841.4),\n",
       "   'text': ' add to the embedding of the second word, in this case something you add to the embedding'},\n",
       "  {'timestamp': (841.4, 842.6), 'text': ' of creature.'},\n",
       "  {'timestamp': (842.6, 847.48),\n",
       "   'text': ' So this value vector lives in the same very high dimensional space as the embeddings.'},\n",
       "  {'timestamp': (847.48, 852.04),\n",
       "   'text': ' When you multiply this value matrix by the embedding of a word, you might think of it as saying'},\n",
       "  {'timestamp': (852.04, 856.92),\n",
       "   'text': ' if this word is relevant to adjusting the meaning of something else, what exactly should'},\n",
       "  {'timestamp': (856.92, 862.2),\n",
       "   'text': ' be added to the embedding of that something else in order to reflect this?'},\n",
       "  {'timestamp': (862.2, 866.4),\n",
       "   'text': \" Looking back in our diagram, let's set aside all of the keys and the queries,\"},\n",
       "  {'timestamp': (866.4, 869.6),\n",
       "   'text': \" since after you compute the attention pattern you're done with those,\"},\n",
       "  {'timestamp': (869.6, 874.0),\n",
       "   'text': \" then you're going to take this value matrix and multiply it by every one of those embeddings\"},\n",
       "  {'timestamp': (874.0, 877.0),\n",
       "   'text': ' to produce a sequence of value vectors.'},\n",
       "  {'timestamp': (877.0, 882.4),\n",
       "   'text': ' You might think of these value vectors as being kind of associated with the corresponding keys.'},\n",
       "  {'timestamp': (882.4, 886.88),\n",
       "   'text': ' For each column in this diagram, you multiply each of the value vectors'},\n",
       "  {'timestamp': (886.88, 892.08),\n",
       "   'text': ' by the corresponding weight in that column. For example, here, under the embedding of'},\n",
       "  {'timestamp': (892.08, 897.04),\n",
       "   'text': ' creature, you would be adding large proportions of the value vectors for fluffy and blue,'},\n",
       "  {'timestamp': (897.04, 901.68),\n",
       "   'text': ' while all of the other value vectors get zeroed out, or at least nearly zeroed out.'},\n",
       "  {'timestamp': (901.68, 906.32),\n",
       "   'text': ' And then finally, the weight to actually update the embedding associated with this column,'},\n",
       "  {'timestamp': (906.32, 909.36),\n",
       "   'text': ' previously encoding some context-free meaning of creature,'},\n",
       "  {'timestamp': (909.36, 912.72),\n",
       "   'text': ' you add together all of these re-scaled values in the column,'},\n",
       "  {'timestamp': (912.72, 916.96),\n",
       "   'text': ' producing a change that you want to add that all labeled Delta E,'},\n",
       "  {'timestamp': (916.96, 919.44),\n",
       "   'text': ' and then you add that to the original embedding.'},\n",
       "  {'timestamp': (919.44, 922.48),\n",
       "   'text': ' Hopefully, what results is a more refined vector'},\n",
       "  {'timestamp': (922.48, 924.88),\n",
       "   'text': ' encoding the more context-ruly-rich meaning,'},\n",
       "  {'timestamp': (924.88, 929.68),\n",
       "   'text': \" like that of a fluffy blue creature. And of course, you don't just do this to one embedding,\"},\n",
       "  {'timestamp': (929.68, 933.6),\n",
       "   'text': ' you apply the same weighted sum across all of the columns in this picture,'},\n",
       "  {'timestamp': (933.6, 939.2),\n",
       "   'text': ' producing a sequence of changes. Adding all of those changes to the corresponding embeddings'},\n",
       "  {'timestamp': (939.2, 943.2),\n",
       "   'text': ' produces a full sequence of more refined embeddings popping out of the attention block.'},\n",
       "  {'timestamp': (944.56, 949.0),\n",
       "   'text': ' Zooming out, this whole process is what you would describe as a single head of attention.'},\n",
       "  {'timestamp': (949.0, 954.0),\n",
       "   'text': \" As I've described things so far, this process is parametrized by three distinct matrices,\"},\n",
       "  {'timestamp': (954.0, 959.0),\n",
       "   'text': ' all filled with tunable parameters, the key, the query, and the value.'},\n",
       "  {'timestamp': (959.0, 963.0),\n",
       "   'text': ' I want to take a moment to continue what we started in the last chapter with the score'},\n",
       "  {'timestamp': (963.0, 969.24),\n",
       "   'text': ' keeping where we count up the total number of model parameters using the numbers from GPT3.'},\n",
       "  {'timestamp': (969.24, 975.24),\n",
       "   'text': ' These key inquiry matrices each have 12,288 columns matching the embedding dimension'},\n",
       "  {'timestamp': (975.24, 980.24),\n",
       "   'text': ' and 128 rows matching the dimension of that smaller key query space.'},\n",
       "  {'timestamp': (980.24, 984.84),\n",
       "   'text': ' This gives us an additional 1.5 million or so parameters for each one.'},\n",
       "  {'timestamp': (984.84, 1006.32),\n",
       "   'text': \" If you look at that value matrix by contrast, the way I've described things so far would suggest that it's a square matrix that has 12,200,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8 about 150 million added parameters. And to be clear,\"},\n",
       "  {'timestamp': (1006.32, 1010.96),\n",
       "   'text': ' you could do that. You could devote orders of magnitude more parameters to the value map than to the'},\n",
       "  {'timestamp': (1010.96, 1015.84),\n",
       "   'text': ' key in query. But in practice, it is much more efficient if instead you make it so that the number'},\n",
       "  {'timestamp': (1015.84, 1021.2),\n",
       "   'text': ' of parameters devoted to this value map is the same as the number devoted to the key in the query.'},\n",
       "  {'timestamp': (1021.2, 1026.2),\n",
       "   'text': ' This is especially relevant in the setting of running multiple attention heads in parallel.'},\n",
       "  {'timestamp': (1026.2, 1031.08),\n",
       "   'text': ' The way this looks is that the value map is factored as a product of two smaller matrices.'},\n",
       "  {'timestamp': (1031.08, 1035.08),\n",
       "   'text': ' Conceptually, I would still encourage you to think about the overall linear map, one with'},\n",
       "  {'timestamp': (1035.08, 1039.68),\n",
       "   'text': ' inputs and outputs, both in this larger embedding space, for example taking the embedding'},\n",
       "  {'timestamp': (1039.68, 1044.44),\n",
       "   'text': \" of blue to this blueness direction that you would add to nouns. It's just that it's\"},\n",
       "  {'timestamp': (1044.44, 1047.0),\n",
       "   'text': ' broken up into two separate steps.'},\n",
       "  {'timestamp': (1047.0, 1050.0),\n",
       "   'text': ' The first matrix on the right here has a smaller number of rows,'},\n",
       "  {'timestamp': (1050.0, 1053.0),\n",
       "   'text': ' typically the same size as the key query space,'},\n",
       "  {'timestamp': (1053.0, 1057.0),\n",
       "   'text': ' what this means is you can think of it as mapping the large embedding vectors'},\n",
       "  {'timestamp': (1057.0, 1059.0), 'text': ' down to a much smaller space.'},\n",
       "  {'timestamp': (1059.0, 1063.0),\n",
       "   'text': \" This is not the conventional naming, but I'm going to call this the value down matrix.\"},\n",
       "  {'timestamp': (1063.0, 1070.0),\n",
       "   'text': ' The second matrix maps from the smaller space back up to the embedding space, producing the vectors that you use to make the actual updates.'},\n",
       "  {'timestamp': (1070.0, 1075.0),\n",
       "   'text': \" I'm going to call this one the value up matrix, which, again, is not conventional.\"},\n",
       "  {'timestamp': (1075.0, 1078.0),\n",
       "   'text': ' The way that you would see this written in most papers looks a little different.'},\n",
       "  {'timestamp': (1078.0, 1083.0),\n",
       "   'text': \" I'll talk about it in a minute, in my opinion, it tends to make things a little more conceptually confusing.\"},\n",
       "  {'timestamp': (1083.0, 1085.26),\n",
       "   'text': ' To throw in linear algebra jargon here,'},\n",
       "  {'timestamp': (1085.26, 1088.48),\n",
       "   'text': \" what we're basically doing is constraining the overall value map\"},\n",
       "  {'timestamp': (1088.48, 1091.36),\n",
       "   'text': ' to be a low-rank transformation.'},\n",
       "  {'timestamp': (1091.36, 1092.96),\n",
       "   'text': ' Turning back to the parameter count,'},\n",
       "  {'timestamp': (1092.96, 1095.76),\n",
       "   'text': ' all four of these matrices have the same size,'},\n",
       "  {'timestamp': (1095.76, 1099.56),\n",
       "   'text': ' and adding them all up, we get about 6.3 million parameters'},\n",
       "  {'timestamp': (1099.56, 1100.96), 'text': ' for one attention head.'},\n",
       "  {'timestamp': (1102.04, 1104.04),\n",
       "   'text': ' As a quick side note, to be a little more accurate,'},\n",
       "  {'timestamp': (1104.04, 1105.4),\n",
       "   'text': ' everything described so far is what'},\n",
       "  {'timestamp': (1105.4, 1109.36),\n",
       "   'text': ' people would call a self-attention head, to distinguish it from a variation that comes'},\n",
       "  {'timestamp': (1109.36, 1112.44),\n",
       "   'text': \" up in other models that's called cross-attention.\"},\n",
       "  {'timestamp': (1112.44, 1116.72),\n",
       "   'text': \" This isn't relevant to our GPT example, but if you're curious, cross-attention involves\"},\n",
       "  {'timestamp': (1116.72, 1121.96),\n",
       "   'text': ' models that process two distinct types of data, like text in one language and text in'},\n",
       "  {'timestamp': (1121.96, 1130.44),\n",
       "   'text': \" another language that's part of an ongoing generation of a translation, or maybe audio input of speech and an ongoing transcription.\"},\n",
       "  {'timestamp': (1130.44, 1133.0),\n",
       "   'text': ' A cross-attention head looks almost identical.'},\n",
       "  {'timestamp': (1133.0, 1137.8),\n",
       "   'text': ' The only difference is that the key and query maps act on different datasets.'},\n",
       "  {'timestamp': (1137.8, 1142.24),\n",
       "   'text': ' In a model-doing translation, for example, the keys might come from one language, while'},\n",
       "  {'timestamp': (1142.24, 1149.52),\n",
       "   'text': ' the queries come from another, and the attention pattern, could describe which words from one language correspond to which words in another.'},\n",
       "  {'timestamp': (1150.16, 1154.0),\n",
       "   'text': \" And in this setting, there would typically be no masking, since there's not really any notion\"},\n",
       "  {'timestamp': (1154.0, 1159.36),\n",
       "   'text': ' of later tokens affecting earlier ones. Staying focused on self-attention, though, if you'},\n",
       "  {'timestamp': (1159.36, 1163.44),\n",
       "   'text': ' understood everything so far, and if you were to stop here, you would come away with the essence'},\n",
       "  {'timestamp': (1163.44, 1165.88), 'text': ' of what attention really is.'},\n",
       "  {'timestamp': (1165.88, 1170.44),\n",
       "   'text': \" All that's really left to us is to lay out the sense in which you do this many many\"},\n",
       "  {'timestamp': (1170.44, 1172.2), 'text': ' different times.'},\n",
       "  {'timestamp': (1172.2, 1176.28),\n",
       "   'text': ' In our central example, we focused on adjectives updating nouns, but of course there'},\n",
       "  {'timestamp': (1176.28, 1180.4),\n",
       "   'text': ' were lots of different ways that context can influence the meaning of a word.'},\n",
       "  {'timestamp': (1180.4, 1187.0),\n",
       "   'text': ' If the words, they crashed the, preceded the word, car, it has implications for the shape and the structure of that car.'},\n",
       "  {'timestamp': (1187.0, 1189.68),\n",
       "   'text': ' And a lot of associations might be less grammatical.'},\n",
       "  {'timestamp': (1189.68, 1196.24),\n",
       "   'text': ' If the word wizard is anywhere in the same passage as Harry, it suggests that this might be referring to Harry Potter.'},\n",
       "  {'timestamp': (1196.24, 1205.04),\n",
       "   'text': ' Whereas if instead, the words queen, Sussex, and William were in that passage, then perhaps the embedding of Harry should instead be updated to refer to the prints.'},\n",
       "  {'timestamp': (1205.04, 1209.28),\n",
       "   'text': ' For every different type of contextual updating that you might imagine, the parameters'},\n",
       "  {'timestamp': (1209.28, 1213.92),\n",
       "   'text': ' of these key inquiry matrices would be different to capture the different attention patterns,'},\n",
       "  {'timestamp': (1213.92, 1219.52),\n",
       "   'text': ' and the parameters of our value map would be different based on what should be added to the embeddings.'},\n",
       "  {'timestamp': (1219.52, 1224.56),\n",
       "   'text': ' And again, in practice, the true behavior of these maps is much more difficult to interpret,'},\n",
       "  {'timestamp': (1224.56, 1228.36),\n",
       "   'text': ' where the weights are set to do whatever the model needs them to do to best accomplish its'},\n",
       "  {'timestamp': (1228.36, 1231.44),\n",
       "   'text': ' goal of predicting the next token.'},\n",
       "  {'timestamp': (1231.44, 1235.56),\n",
       "   'text': ' As I said before, everything were described as a single head of attention, and a full'},\n",
       "  {'timestamp': (1235.56, 1240.44),\n",
       "   'text': \" attention block inside a transformer consists of what's called multi-headed attention, where\"},\n",
       "  {'timestamp': (1240.44, 1244.96),\n",
       "   'text': ' you run a lot of these operations in parallel, each with its own distinct key query and'},\n",
       "  {'timestamp': (1244.96, 1246.0), 'text': ' value maps.'},\n",
       "  {'timestamp': (1247.0, 1252.0),\n",
       "   'text': ' GPT-3, for example, uses 96 attention heads inside each block.'},\n",
       "  {'timestamp': (1252.0, 1257.0),\n",
       "   'text': \" Considering that each one is already a bit confusing, it's certainly a lot to hold in your head.\"},\n",
       "  {'timestamp': (1257.0, 1262.0),\n",
       "   'text': ' Just to spell it all out very explicitly, this means you have 96 distinct key and query matrices,'},\n",
       "  {'timestamp': (1262.0, 1265.44),\n",
       "   'text': ' producing 96 distinct attention patterns.'},\n",
       "  {'timestamp': (1265.44, 1271.24),\n",
       "   'text': ' Then each head has its own distinct value matrices, used to produce 96 sequences of'},\n",
       "  {'timestamp': (1271.24, 1272.8), 'text': ' value vectors.'},\n",
       "  {'timestamp': (1272.8, 1277.52),\n",
       "   'text': ' These are all added together using the corresponding attention patterns as weights.'},\n",
       "  {'timestamp': (1277.52, 1282.44),\n",
       "   'text': ' What this means is that for each position in the context, each token, every one of these'},\n",
       "  {'timestamp': (1282.44, 1285.76),\n",
       "   'text': ' heads produces a proposed change to be added to the'},\n",
       "  {'timestamp': (1285.76, 1291.28),\n",
       "   'text': ' embedding in that position. So what you do is you sum together all of those proposed changes,'},\n",
       "  {'timestamp': (1291.28, 1295.36),\n",
       "   'text': ' one for each head, and you add the result to the original embedding of that position.'},\n",
       "  {'timestamp': (1296.48, 1303.28),\n",
       "   'text': \" This entire sum here would be one slice of what's outputted from this multi-headed attention block,\"},\n",
       "  {'timestamp': (1303.28, 1305.96),\n",
       "   'text': ' a single one of those refined embeddings'},\n",
       "  {'timestamp': (1305.96, 1308.24),\n",
       "   'text': ' that pops out the other end of it.'},\n",
       "  {'timestamp': (1308.24, 1309.84),\n",
       "   'text': ' Again, this is a lot to think about,'},\n",
       "  {'timestamp': (1309.84, 1312.48),\n",
       "   'text': \" so don't worry at all if it takes some time to sink in.\"},\n",
       "  {'timestamp': (1312.48, 1315.2),\n",
       "   'text': ' The overall idea is that by running many distinct heads'},\n",
       "  {'timestamp': (1315.2, 1318.28),\n",
       "   'text': \" in parallel, you're giving the model the capacity\"},\n",
       "  {'timestamp': (1318.28, 1321.96),\n",
       "   'text': ' to learn many distinct ways that context changes meaning.'},\n",
       "  {'timestamp': (1323.64, 1325.96),\n",
       "   'text': ' Pulling up our running tally for parameter count,'},\n",
       "  {'timestamp': (1325.96, 1330.2),\n",
       "   'text': ' with 96 heads, each including its own variation of these four matrices,'},\n",
       "  {'timestamp': (1330.2, 1332.48),\n",
       "   'text': ' each block of multi-headed attention'},\n",
       "  {'timestamp': (1332.48, 1335.24),\n",
       "   'text': ' ends up with around 600 million parameters.'},\n",
       "  {'timestamp': (1336.24, 1339.2),\n",
       "   'text': \" There's one added slightly annoying thing that I should really mention\"},\n",
       "  {'timestamp': (1339.2, 1342.04),\n",
       "   'text': ' for any of you who go on to read more about transformers.'},\n",
       "  {'timestamp': (1342.04, 1344.68),\n",
       "   'text': ' You remember how I said that the value map is factored out'},\n",
       "  {'timestamp': (1344.68, 1348.52),\n",
       "   'text': ' into these two distinct matrices, which I labeled as the value down and the value'},\n",
       "  {'timestamp': (1348.52, 1349.88), 'text': ' up matrices.'},\n",
       "  {'timestamp': (1349.88, 1354.6),\n",
       "   'text': ' The way that I framed things would suggest that you see this pair of matrices inside'},\n",
       "  {'timestamp': (1354.6, 1359.16),\n",
       "   'text': ' each attention head, and you could absolutely implement it this way, that would be a'},\n",
       "  {'timestamp': (1359.16, 1360.36), 'text': ' valid design.'},\n",
       "  {'timestamp': (1360.36, 1363.96),\n",
       "   'text': \" But the way that you see this written in papers and the way that it's implemented in practice\"},\n",
       "  {'timestamp': (1363.96, 1370.0),\n",
       "   'text': ' looks a little different. All of these value up matrices for each head appear stapled together'},\n",
       "  {'timestamp': (1370.0, 1375.44),\n",
       "   'text': ' in one giant matrix that we call the output matrix, associated with the entire multi-headed'},\n",
       "  {'timestamp': (1375.44, 1380.08),\n",
       "   'text': ' attention block. And when you see people refer to the value matrix for a given attention head,'},\n",
       "  {'timestamp': (1380.08, 1387.0),\n",
       "   'text': \" they're typically only referring to this first step, the one that I was labeling as the value down, projection into the smaller space.\"},\n",
       "  {'timestamp': (1388.0, 1391.0),\n",
       "   'text': \" For the curious among you, I've left an on-screen note about it.\"},\n",
       "  {'timestamp': (1391.0, 1395.0),\n",
       "   'text': \" It's one of those details that runs the risk of distracting from the main conceptual points,\"},\n",
       "  {'timestamp': (1395.0, 1399.0),\n",
       "   'text': ' but I do want to call it out just so that you know if you read about this in other sources.'},\n",
       "  {'timestamp': (1399.0, 1403.0),\n",
       "   'text': ' Setting aside all the technical nuances in the preview from the last chapter,'},\n",
       "  {'timestamp': (1403.0, 1409.84),\n",
       "   'text': \" we saw how data flowing through a transformer doesn't just flow through a single attention block. For one thing, it also goes through\"},\n",
       "  {'timestamp': (1409.84, 1414.88),\n",
       "   'text': \" these other operations called multilayer perceptrons, we'll talk more about those in the next chapter,\"},\n",
       "  {'timestamp': (1414.88, 1420.64),\n",
       "   'text': ' and then it repeatedly goes through many many copies of both of these operations. What this means'},\n",
       "  {'timestamp': (1420.64, 1425.8),\n",
       "   'text': ' is that after a given word imbibes some of its context, there are many more chances'},\n",
       "  {'timestamp': (1425.8, 1430.88),\n",
       "   'text': ' for this more nuanced embedding to be influenced by its more nuanced surroundings.'},\n",
       "  {'timestamp': (1430.88, 1435.12),\n",
       "   'text': ' The further down the network you go, with each embedding, taking in more and more meaning'},\n",
       "  {'timestamp': (1435.12, 1439.12),\n",
       "   'text': ' from all the other embeddings, which themselves are getting more and more nuanced,'},\n",
       "  {'timestamp': (1439.12, 1443.64),\n",
       "   'text': \" the hope is that there's the capacity to encode higher level and more abstract ideas about\"},\n",
       "  {'timestamp': (1443.64, 1445.32), 'text': ' a given input beyond just'},\n",
       "  {'timestamp': (1445.32, 1451.04),\n",
       "   'text': \" descriptors and grammatical structure. Things like sentiment and tone and whether it's a poem\"},\n",
       "  {'timestamp': (1451.04, 1456.72),\n",
       "   'text': ' and what underlying scientific truths are relevant to the piece and things like that.'},\n",
       "  {'timestamp': (1456.72, 1462.84),\n",
       "   'text': ' Turning back one more time to our scorekeeping, GPT-3 includes 96 distinct layers, so the'},\n",
       "  {'timestamp': (1462.84, 1466.4),\n",
       "   'text': ' total number of key query and value parameters is multiplied'},\n",
       "  {'timestamp': (1466.4, 1473.08),\n",
       "   'text': ' by another 96, which brings the total sum to just under 58 billion distinct parameters devoted'},\n",
       "  {'timestamp': (1473.08, 1475.08), 'text': ' to all of the attention heads.'},\n",
       "  {'timestamp': (1475.08, 1479.92),\n",
       "   'text': \" That is a lot to be sure, but it's only about a third of the 175 billion that are in\"},\n",
       "  {'timestamp': (1479.92, 1481.6), 'text': ' the network in total.'},\n",
       "  {'timestamp': (1481.6, 1485.52),\n",
       "   'text': ' So even though attention gets all of the attention, the majority of parameters'},\n",
       "  {'timestamp': (1485.52, 1489.92),\n",
       "   'text': ' come from the blocks sitting in between these steps. In the next chapter, you and I will talk'},\n",
       "  {'timestamp': (1489.92, 1494.64),\n",
       "   'text': ' more about those other blocks and also a lot more about the training process. A big part of the'},\n",
       "  {'timestamp': (1494.64, 1499.92),\n",
       "   'text': ' story for the success of the attention mechanism is not so much any specific kind of behavior'},\n",
       "  {'timestamp': (1499.92, 1509.36),\n",
       "   'text': \" that enables, but the fact that it's extremely parallelizable, meaning that you can run a huge number of computations in a short time using GPUs.\"},\n",
       "  {'timestamp': (1509.36, 1512.68),\n",
       "   'text': ' Given that one of the big lessons about deep learning in the last decade or two has'},\n",
       "  {'timestamp': (1512.68, 1517.52),\n",
       "   'text': ' been that scale alone seems to give huge qualitative improvements in model performance,'},\n",
       "  {'timestamp': (1517.52, 1522.16),\n",
       "   'text': \" there's a huge advantage to parallelizable architectures that let you do this.\"},\n",
       "  {'timestamp': (1522.16, 1525.68),\n",
       "   'text': \" If you want to learn more about this stuff, I've left lots of links in the description.\"},\n",
       "  {'timestamp': (1525.68, 1530.4),\n",
       "   'text': ' In particular, anything produced by Andre Carpathia, Chris Ola, tend to be pure gold.'},\n",
       "  {'timestamp': (1530.4, 1533.84),\n",
       "   'text': ' In this video, I wanted to just jump into attention in its current form,'},\n",
       "  {'timestamp': (1533.84, 1537.52),\n",
       "   'text': \" but if you're curious about more of the history for how we got here and how you might reinvent\"},\n",
       "  {'timestamp': (1537.52, 1541.76),\n",
       "   'text': ' this idea for yourself, my friend Vivek just put up a couple videos, giving a lot more of that'},\n",
       "  {'timestamp': (1541.76, 1548.48),\n",
       "   'text': ' motivation. Also, Britt Cruz from the channel The art of the problem has a really nice video about the history of large language models.'},\n",
       "  {'timestamp': (1564.17, 1566.17), 'text': ' you'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JAXed up\n",
    "text = pipeline(\"test.mp3\", return_timestamps=True)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'In the last chapter, you and I started to step through the internal workings of a transformer.', 'start': 0.0, 'end': 4.4}, {'text': 'This is one of the key pieces of technology inside large language models,', 'start': 4.4, 'end': 7.84}, {'text': 'and a lot of other tools in the modern way of AI.', 'start': 7.84, 'end': 10.8}, {'text': 'It first hit the scene and a now-famous 2017 paper called Attention as All You Need,', 'start': 10.8, 'end': 15.52}, {'text': 'and in this chapter, you and I will dig into what this attention mechanism is,', 'start': 15.52, 'end': 19.68}, {'text': 'visualizing how it processes data.', 'start': 19.68, 'end': 21.6}, {'text': \"As a quick recap, here's the important context I want you to have in mind.\", 'start': 26.48, 'end': 30.12}, {'text': 'The goal of the model that you and I are studying is to take in a piece of text and predict', 'start': 30.12, 'end': 34.72}, {'text': 'what word comes next.', 'start': 34.72, 'end': 36.8}, {'text': 'The input text is broken up into little pieces that we call tokens, and these are very', 'start': 36.8, 'end': 41.04}, {'text': 'often words or pieces of words, but just to make the examples in this video easier for you and me to think about,', 'start': 41.04, 'end': 47.0}, {'text': \"let's simplify by pretending that tokens are always just words.\", 'start': 47.0, 'end': 51.0}, {'text': 'The first step in a transformer is to associate each token with a high-dimensional vector, what we call its embedding.', 'start': 51.0, 'end': 58.0}, {'text': 'Now the most important idea I want you to have in mind is how directions in this high-dimensional space of all possible embeddings can correspond', 'start': 58.0, 'end': 65.8}, {'text': 'with semantic meaning. In the last chapter we saw an example for how direction can correspond', 'start': 65.8, 'end': 70.6}, {'text': 'to gender, in the sense that adding a certain step in this space can take you from the embedding', 'start': 70.6, 'end': 75.8}, {'text': \"of a masculine noun to the embedding of the corresponding feminine noun. That's just one\", 'start': 75.8, 'end': 80.52}, {'text': 'example you could imagine how many other directions in this high-dimensional space could', 'start': 80.52, 'end': 84.72}, {'text': \"correspond to numerous other aspects of a word's meaning.\", 'start': 84.72, 'end': 87.56}, {'text': \"The aim of a transformer is to progressively adjust these embeddings so that they don't merely encode an individual word,\", 'start': 88.56, 'end': 95.52}, {'text': 'but instead they bacon some much much richer contextual meaning.', 'start': 95.52, 'end': 99.2}, {'text': \"I should say a front that a lot of people find the attention mechanism, this key piece in a transformer, very confusing, so don't worry if it takes some time for things to sink in.\", 'start': 99.92, 'end': 108.64}, {'text': 'I think that before we dive into the computational details and all the matrix multiplications,', 'start': 109.36, 'end': 113.76}, {'text': \"it's worth thinking about a couple of examples for the kind of behavior that we want attention\", 'start': 113.76, 'end': 118.24}, {'text': 'to enable. Consider the phrases American true, Mal, one mole of carbon dioxide, and take a biopsy of the mole.', 'start': 118.24, 'end': 126.68}, {'text': 'You and I know that the word mole has different meanings in each one of these, based on the context.', 'start': 126.68, 'end': 131.4}, {'text': 'But after the first step of a transformer, the one that breaks up the text and associate', 'start': 131.4, 'end': 135.04}, {'text': \"see each token with a vector, the vector that's associated with mole would be the same in all three of these cases,\", 'start': 135.04, 'end': 141.4}, {'text': \"because this initial token embedding is effectively a look-up table with no reference to the context. It's only in the next step of the transformer that the surrounding\", 'start': 141.4, 'end': 150.16}, {'text': 'embeddings have the chance to pass information into this one. The picture you might have', 'start': 150.16, 'end': 154.56}, {'text': 'in mind is that there are multiple distinct directions in this embedding space,', 'start': 154.56, 'end': 158.24}, {'text': 'encoding the multiple distinct meanings of the word mall, and that a well-trained attention', 'start': 158.24, 'end': 162.8}, {'text': 'block calculates what you need to add', 'start': 162.8, 'end': 165.28}, {'text': 'to the generic embedding to move it to one of these more specific directions as a function of the context.', 'start': 165.28, 'end': 171.6}, {'text': 'To take another example, consider the embedding of the word tower. This is presumably', 'start': 172.96, 'end': 177.6}, {'text': 'some very generic non-specific direction in the space associated with lots of other large tall', 'start': 177.6, 'end': 182.88}, {'text': 'nouns. If this word was immediately preceded by Eiffel, you could imagine wanting the mechanism', 'start': 182.88, 'end': 188.64}, {'text': 'to update this vector so that it points in a direction that more specifically encodes', 'start': 188.64, 'end': 193.36}, {'text': 'the Eiffel Tower, maybe correlated with vectors associated with Paris and France and things', 'start': 193.36, 'end': 198.28}, {'text': 'made of steel.', 'start': 198.28, 'end': 199.92}, {'text': 'If it was also preceded by the word miniature, then the vector should be updated even further', 'start': 199.92, 'end': 204.72}, {'text': 'so that it no longer correlates with large tall things.', 'start': 204.72, 'end': 209.62}, {'text': 'More generally than just refining the meaning of a word, the attention block allows the model', 'start': 209.62, 'end': 213.78}, {'text': 'to move information encoded in one embedding to that of another, potentially ones that', 'start': 213.78, 'end': 218.74}, {'text': \"are quite far away, and potentially with information that's much richer than just a single\", 'start': 218.74, 'end': 222.82}, {'text': 'word.', 'start': 222.82, 'end': 224.02}, {'text': 'What we saw in the last chapter was how after all of the vectors flow through the network,', 'start': 224.02, 'end': 228.0}, {'text': 'including many different attention blocks.', 'start': 228.0, 'end': 230.0}, {'text': 'The computation that you perform to produce a prediction of the next token is entirely a function', 'start': 230.0, 'end': 236.4}, {'text': 'of the last vector in the sequence.', 'start': 236.4, 'end': 239.0}, {'text': 'So imagine, for example, that the text you input is most of an entire mystery novel,', 'start': 239.0, 'end': 243.6}, {'text': 'all the way up to a point near the end,', 'start': 243.6, 'end': 245.4}, {'text': 'which reads, therefore the murderer was,', 'start': 245.4, 'end': 248.48}, {'text': \"if the model's going to accurately predict the next word,\", 'start': 248.48, 'end': 251.28}, {'text': 'that final vector in the sequence,', 'start': 251.28, 'end': 253.04}, {'text': 'which began its life simply embedding the word was,', 'start': 253.04, 'end': 256.32}, {'text': 'will have to have been updated by all of the attention blocks', 'start': 256.32, 'end': 259.24}, {'text': 'to represent much more than any individual word,', 'start': 259.24, 'end': 262.4}, {'text': 'somehow encoding all of the information', 'start': 262.4, 'end': 264.56}, {'text': \"from the full context window that's relevant\", 'start': 264.56, 'end': 266.88}, {'text': 'to predicting the next word.', 'start': 266.88, 'end': 268.4}, {'text': 'To step through the computations though,', 'start': 269.48, 'end': 270.96}, {'text': \"let's take a much simpler example,\", 'start': 270.96, 'end': 272.92}, {'text': 'imagine that the input includes the phrase,', 'start': 272.92, 'end': 275.24}, {'text': 'a fluffy blue creature roamed the word in forest.', 'start': 275.24, 'end': 278.48}, {'text': 'And for the moment,', 'start': 278.48, 'end': 279.36}, {'text': 'suppose that the only type of update that we care about', 'start': 279.36, 'end': 282.32}, {'text': 'is having the adjectives adjust the meanings', 'start': 282.32, 'end': 284.88}, {'text': 'of their corresponding nouns.', 'start': 284.88, 'end': 286.96}, {'text': \"What I'm about to describe is what we would call a single head of attention, and later\", 'start': 286.96, 'end': 291.52}, {'text': 'we will see how the attention block consists of many different heads run in parallel.', 'start': 291.52, 'end': 296.12}, {'text': 'Again, the initial embedding for each word is some high dimensional vector that only encodes', 'start': 296.12, 'end': 300.56}, {'text': 'the meaning of that particular word with no context.', 'start': 300.56, 'end': 303.96}, {'text': \"Actually, that's not quite true. They also encode the meaning of that particular word with no context. Actually, that's not quite true.\", 'start': 303.96, 'end': 305.5}, {'text': 'They also encode the position of the word.', 'start': 305.5, 'end': 308.0}, {'text': \"There's a lot more to say about the specific way the positions are encoded, but right\", 'start': 308.0, 'end': 311.84}, {'text': 'now, all you need to know is that the entries of this vector are enough to tell you both what', 'start': 311.84, 'end': 316.04}, {'text': 'the word is and where it exists in the context.', 'start': 316.04, 'end': 319.44}, {'text': \"Let's go ahead and denote these embeddings with the letter E.\", 'start': 319.44, 'end': 322.4}, {'text': 'The goal is to have a series of computations, produce a new refined set of embeddings, where for example those corresponding to the nouns', 'start': 322.4, 'end': 329.76}, {'text': 'have ingested the meaning from their corresponding adjectives. And playing the deep learning', 'start': 329.76, 'end': 334.88}, {'text': 'game, we want most of the computations involved to look like matrix vector products, where', 'start': 334.88, 'end': 339.52}, {'text': 'the matrices are full of tunable weights, things that the model will learn based on data.', 'start': 339.52, 'end': 343.76}, {'text': \"To be clear, I'm making up this example of adjectives updating nouns just to illustrate\", 'start': 344.48, 'end': 348.92}, {'text': 'the type of behavior that you could imagine an intention had to do.', 'start': 348.92, 'end': 352.96}, {'text': \"As with so much deep learning, the true behavior is much harder to parse, because it's\", 'start': 352.96, 'end': 356.6}, {'text': 'based on tweaking and tuning, a huge number of parameters to minimize some cost function.', 'start': 356.6, 'end': 361.96}, {'text': \"It's just that as we step through all of the different matrices filled with parameters that are involved in this process, I think it's really helpful to have\", 'start': 361.96, 'end': 368.72}, {'text': 'an imagined example of something that it could be doing to help keep it all more concrete.', 'start': 368.72, 'end': 373.12}, {'text': 'For the first step of this process, you might imagine each noun, like creature,', 'start': 373.92, 'end': 377.92}, {'text': 'asking the question, hey, are there any adjectives sitting in front of me? And for the words', 'start': 377.92, 'end': 382.88}, {'text': \"fluffy and blue, to each be able to answer, yeah, I'm an adjective,\", 'start': 382.88, 'end': 387.04}, {'text': \"and I'm in that position.\", 'start': 387.04, 'end': 388.24}, {'text': 'That question is somehow encoded as yet another vector,', 'start': 389.32, 'end': 392.52}, {'text': 'another list of numbers, which we call the query for this word.', 'start': 392.52, 'end': 396.8}, {'text': 'This query vector, though,', 'start': 396.8, 'end': 398.04}, {'text': 'has a much smaller dimension than the embedding vector,', 'start': 398.04, 'end': 400.84}, {'text': 'say 128.', 'start': 400.84, 'end': 402.84}, {'text': 'Computing this query looks like taking a certain matrix, which all labeled', 'start': 402.84, 'end': 406.18}, {'text': \"WQ, and multiplying it by the embedding. Compressing things a bit, let's write that\", 'start': 406.18, 'end': 412.48}, {'text': 'query vector as Q, and then anytime you see me put a matrix next to an arrow like this', 'start': 412.48, 'end': 417.82}, {'text': \"one, it's meant to represent that multiplying this matrix by the vector at the arrows\", 'start': 417.82, 'end': 422.24}, {'text': 'start, gives you the vector at the arrows end. In this case, you multiply this matrix by the vector at the arrows start, gives you the vector at the arrows end.', 'start': 422.24, 'end': 426.0}, {'text': 'In this case, you multiply this matrix by all of the embeddings in the context, producing one query vector for each token. The entries of this matrix are parameters of the model,', 'start': 430.0, 'end': 436.32}, {'text': 'which means the true behavior is learned from data, and in practice what this matrix does in a', 'start': 436.32, 'end': 440.8}, {'text': 'particular attention head is challenging to parse. But for R-sake, imagining an example that we might hope that it would learn, will suppose', 'start': 440.8, 'end': 447.94}, {'text': 'that this query matrix maps the embeddings of nouns to certain directions in this smaller', 'start': 447.94, 'end': 452.6}, {'text': 'query space that somehow encodes the notion of looking for adjectives in preceding positions.', 'start': 452.6, 'end': 458.92}, {'text': 'As to what it does to other embeddings, who knows?', 'start': 458.92, 'end': 461.72}, {'text': 'Maybe it simultaneously tries to accomplish some other goal with those, right now, where laser focused on the nouns.', 'start': 461.72, 'end': 467.32}, {'text': 'At the same time, associated with this is a second matrix called the key matrix, which', 'start': 467.32, 'end': 472.2}, {'text': 'you also multiply by every one of the embeddings.', 'start': 472.2, 'end': 475.28}, {'text': 'This produces a second sequence of vectors that we call the keys.', 'start': 475.28, 'end': 479.36}, {'text': 'Conceptually, you want to think of the keys as potentially answering the queries.', 'start': 479.36, 'end': 483.96}, {'text': 'This key matrix is also full of tunable parameters, and just like the query matrix, it maps the embedding vectors to that', 'start': 483.96, 'end': 489.52}, {'text': 'same smaller dimensional space. You think of the keys as matching the queries, whenever they', 'start': 489.52, 'end': 495.2}, {'text': 'closely align with each other. In our example, you would imagine that the key matrix maps the', 'start': 495.2, 'end': 500.08}, {'text': 'adjectives, like fluffy and blue, to vectors that are closely aligned with the query', 'start': 500.08, 'end': 505.28}, {'text': 'produced by the word creature.', 'start': 505.28, 'end': 507.6}, {'text': 'To measure how well each key matches each query, you compute a dot product between each', 'start': 507.6, 'end': 512.44}, {'text': 'possible key query pair.', 'start': 512.44, 'end': 514.88}, {'text': 'I like to visualize a grid full of a bunch of dots where the bigger dots correspond to', 'start': 514.88, 'end': 519.2}, {'text': 'the larger dot products, the places where the keys and queries align.', 'start': 519.2, 'end': 523.4}, {'text': 'For our adjective noun example, that would look a little more like this, places where the keys and queries align. For our adjective noun example,', 'start': 523.4, 'end': 525.12}, {'text': 'that would look a little more like this, where if the keys produced by fluffy and blue', 'start': 525.12, 'end': 530.4}, {'text': 'really do align closely with the query produced by creature, then the dot products in these two', 'start': 530.4, 'end': 535.6}, {'text': 'spots would be some large positive numbers. In the lingo machine learning people would say that', 'start': 535.6, 'end': 541.04}, {'text': 'this means the embeddings of fluffy and blue attend to the embedding of creature. By contrast, the dot product between the key for some other words, like the', 'start': 541.04, 'end': 550.24}, {'text': 'and the query for creature, would be some small or negative value that reflects that these are', 'start': 550.24, 'end': 555.28}, {'text': 'unrelated to each other. So we have this grid of values that can be any real number from negative', 'start': 555.28, 'end': 561.44}, {'text': 'infinity to infinity, giving us a score for how relevant', 'start': 561.44, 'end': 565.28}, {'text': 'each word is to updating the meaning of every other word.', 'start': 565.28, 'end': 569.16}, {'text': \"The way we're about to use these scores is to take a certain weighted sum along each\", 'start': 569.16, 'end': 573.48}, {'text': 'column, weighted by the relevance.', 'start': 573.48, 'end': 576.48}, {'text': 'So instead of having values range from negative infinity to infinity, what we want is for', 'start': 576.48, 'end': 580.96}, {'text': 'the numbers in these columns to be between 0 and 1, and for each column to add up to 1, as if they were a probability distribution.', 'start': 580.96, 'end': 589.28}, {'text': \"If you're coming in from the last chapter, you know what we need to do then.\", 'start': 589.28, 'end': 592.6}, {'text': 'We compute a softmax along each one of these columns to normalize the values.', 'start': 592.6, 'end': 600.36}, {'text': \"In our picture, after you apply softmax to all of the columns, we'll fill in the grid\", 'start': 600.36, 'end': 604.32}, {'text': 'with these normalized values.', 'start': 604.32, 'end': 606.0}, {'text': \"At this point, you're safe to think about each column as giving weights, according to how relevant the word on the left is to the corresponding value at the top.\", 'start': 606.0, 'end': 615.0}, {'text': 'We call this grid an attention pattern.', 'start': 615.0, 'end': 618.0}, {'text': \"Now if you look at the original transformer paper, there's a really compact way that they write this all down. Here, the variable's Q and K represent the full arrays of query and key vectors\", 'start': 618.0, 'end': 629.76}, {'text': 'respectively. Those little vectors you get by multiplying the embeddings by the query and the', 'start': 629.76, 'end': 633.84}, {'text': 'key matrices. This expression up in the numerator is a really compact way to represent the grid', 'start': 633.84, 'end': 639.36}, {'text': \"of all possible dot products between pairs of keys and queries. A small technical detail that I didn't mention is that for numerical stability, it happens\", 'start': 639.36, 'end': 648.28}, {'text': 'to be helpful to divide all of these values by the square root of the dimension in that', 'start': 648.28, 'end': 652.9}, {'text': 'key query space.', 'start': 652.9, 'end': 654.82}, {'text': \"Then this softmax that's wrapped around the full expression is meant to be understood to\", 'start': 654.82, 'end': 659.2}, {'text': 'apply column by column.', 'start': 659.2, 'end': 661.76}, {'text': \"As to that V term, we'll talk about it in just a second. Before that, there's\", 'start': 661.76, 'end': 665.76}, {'text': \"one other technical detail that so far I've skipped. During the training process, when you run\", 'start': 665.76, 'end': 670.56}, {'text': 'this model on a given text example, and all of the weights are slightly adjusted in tune', 'start': 670.56, 'end': 675.12}, {'text': 'to either reward or punish it, based on how high a probability it assigns to the true next', 'start': 675.12, 'end': 679.6}, {'text': 'word in the passage. It turns out to make the whole training process a lot more efficient,', 'start': 679.6, 'end': 683.76}, {'text': 'if you simultaneously', 'start': 683.76, 'end': 685.04}, {'text': 'have it predict every possible next token, following each initial sub-sequence of tokens in this', 'start': 685.04, 'end': 690.88}, {'text': \"passage. For example, with the phrase that we've been focusing on, it might also be predicting\", 'start': 690.88, 'end': 695.68}, {'text': 'what words follow creature and what words follow the. This is really nice because it means what', 'start': 695.68, 'end': 701.68}, {'text': 'would otherwise be a single training example, effectively acts as many.', 'start': 701.68, 'end': 705.84}, {'text': 'For the purposes of our attention pattern, it means that you never want to allow later words to influence earlier words,', 'start': 705.84, 'end': 712.56}, {'text': 'since otherwise they could kind of give away the answer for what comes next.', 'start': 712.56, 'end': 716.24}, {'text': 'What this means is that we want all of these spots here, the ones representing later tokens, influencing earlier ones,', 'start': 716.24, 'end': 722.56}, {'text': 'to somehow be forced to be zero.', 'start': 722.56, 'end': 724.56}, {'text': 'The simplest thing you might think to do is to set the meacul to zero, but if you did', 'start': 725.92, 'end': 729.32}, {'text': \"that, the columns wouldn't add up to one anymore, they wouldn't be normalized.\", 'start': 729.32, 'end': 733.08}, {'text': 'So instead, a common way to do this is that before applying softbacks, you set all of', 'start': 733.08, 'end': 737.28}, {'text': 'those entries to be negative infinity.', 'start': 737.28, 'end': 739.68}, {'text': 'If you do that, then after applying softmax, all of those get turned into zero, but the', 'start': 739.68, 'end': 743.92}, {'text': 'columns stay normalized.', 'start': 743.92, 'end': 746.12}, {'text': 'This process is called masking.', 'start': 746.12, 'end': 747.84}, {'text': \"There are versions of attention where you don't apply it, but in our GPT example, even though\", 'start': 747.84, 'end': 752.08}, {'text': 'this is more relevant during the training phase than it would be, say, running it as a chat', 'start': 752.08, 'end': 755.92}, {'text': 'bot or something like that, you do always apply this masking to prevent later tokens', 'start': 755.92, 'end': 759.76}, {'text': 'from influencing earlier ones.', 'start': 759.76, 'end': 762.52}, {'text': \"Another fact that's worth reflecting on about this attention pattern is how its size\", 'start': 762.52, 'end': 766.92}, {'text': 'is equal to the square of the context size.', 'start': 766.92, 'end': 769.88}, {'text': 'So this is why context size can be a really huge bottleneck for large language models,', 'start': 769.88, 'end': 774.04}, {'text': 'and scaling it up is non-trivial.', 'start': 774.04, 'end': 776.4}, {'text': 'As you might imagine, motivated by a desire for bigger and bigger context windows, recent', 'start': 776.4, 'end': 780.72}, {'text': 'years have seen some variations to the attention mechanism aimed at making context more scalable, but right here, you and I are staying focused on the basics.', 'start': 780.72, 'end': 789.18}, {'text': 'Okay, great, computing this pattern lets the model deduce which words are relevant to', 'start': 789.18, 'end': 794.66}, {'text': 'which other words.', 'start': 794.66, 'end': 796.06}, {'text': 'Now you need to actually update the embeddings, allowing words to pass information to whichever', 'start': 796.06, 'end': 800.96}, {'text': \"other words they're relevant to.\", 'start': 800.96, 'end': 803.08}, {'text': 'For example, you want the embedding of fluffy to somehow cause a change to creature', 'start': 803.08, 'end': 808.0}, {'text': 'that moves it to a different part of this 12,000 dimensional embedding space that more', 'start': 808.0, 'end': 812.44}, {'text': 'specifically encodes a fluffy creature.', 'start': 812.44, 'end': 815.44}, {'text': \"What I'm going to do here is first show you the most straightforward way that you could\", 'start': 815.44, 'end': 818.72}, {'text': \"do this, though there's a slight way that this gets modified in the context of multi-headed\", 'start': 818.72, 'end': 822.88}, {'text': 'attention.', 'start': 822.88, 'end': 824.16}, {'text': 'This most straightforward way would be to use a third matrix, what we call the value matrix,', 'start': 824.16, 'end': 829.12}, {'text': 'which you multiply by the embedding of that first word, for example, Fluffy.', 'start': 829.12, 'end': 833.4}, {'text': 'The result of this is what you would call a value vector, and this is something that you', 'start': 833.4, 'end': 837.44}, {'text': 'add to the embedding of the second word, in this case something you add to the embedding', 'start': 837.44, 'end': 841.4}, {'text': 'of creature.', 'start': 841.4, 'end': 842.6}, {'text': 'So this value vector lives in the same very high dimensional space as the embeddings.', 'start': 842.6, 'end': 847.48}, {'text': 'When you multiply this value matrix by the embedding of a word, you might think of it as saying', 'start': 847.48, 'end': 852.04}, {'text': 'if this word is relevant to adjusting the meaning of something else, what exactly should', 'start': 852.04, 'end': 856.92}, {'text': 'be added to the embedding of that something else in order to reflect this?', 'start': 856.92, 'end': 862.2}, {'text': \"Looking back in our diagram, let's set aside all of the keys and the queries,\", 'start': 862.2, 'end': 866.4}, {'text': \"since after you compute the attention pattern you're done with those,\", 'start': 866.4, 'end': 869.6}, {'text': \"then you're going to take this value matrix and multiply it by every one of those embeddings\", 'start': 869.6, 'end': 874.0}, {'text': 'to produce a sequence of value vectors.', 'start': 874.0, 'end': 877.0}, {'text': 'You might think of these value vectors as being kind of associated with the corresponding keys.', 'start': 877.0, 'end': 882.4}, {'text': 'For each column in this diagram, you multiply each of the value vectors', 'start': 882.4, 'end': 886.88}, {'text': 'by the corresponding weight in that column. For example, here, under the embedding of', 'start': 886.88, 'end': 892.08}, {'text': 'creature, you would be adding large proportions of the value vectors for fluffy and blue,', 'start': 892.08, 'end': 897.04}, {'text': 'while all of the other value vectors get zeroed out, or at least nearly zeroed out.', 'start': 897.04, 'end': 901.68}, {'text': 'And then finally, the weight to actually update the embedding associated with this column,', 'start': 901.68, 'end': 906.32}, {'text': 'previously encoding some context-free meaning of creature,', 'start': 906.32, 'end': 909.36}, {'text': 'you add together all of these re-scaled values in the column,', 'start': 909.36, 'end': 912.72}, {'text': 'producing a change that you want to add that all labeled Delta E,', 'start': 912.72, 'end': 916.96}, {'text': 'and then you add that to the original embedding.', 'start': 916.96, 'end': 919.44}, {'text': 'Hopefully, what results is a more refined vector', 'start': 919.44, 'end': 922.48}, {'text': 'encoding the more context-ruly-rich meaning,', 'start': 922.48, 'end': 924.88}, {'text': \"like that of a fluffy blue creature. And of course, you don't just do this to one embedding,\", 'start': 924.88, 'end': 929.68}, {'text': 'you apply the same weighted sum across all of the columns in this picture,', 'start': 929.68, 'end': 933.6}, {'text': 'producing a sequence of changes. Adding all of those changes to the corresponding embeddings', 'start': 933.6, 'end': 939.2}, {'text': 'produces a full sequence of more refined embeddings popping out of the attention block.', 'start': 939.2, 'end': 943.2}, {'text': 'Zooming out, this whole process is what you would describe as a single head of attention.', 'start': 944.56, 'end': 949.0}, {'text': \"As I've described things so far, this process is parametrized by three distinct matrices,\", 'start': 949.0, 'end': 954.0}, {'text': 'all filled with tunable parameters, the key, the query, and the value.', 'start': 954.0, 'end': 959.0}, {'text': 'I want to take a moment to continue what we started in the last chapter with the score', 'start': 959.0, 'end': 963.0}, {'text': 'keeping where we count up the total number of model parameters using the numbers from GPT3.', 'start': 963.0, 'end': 969.24}, {'text': 'These key inquiry matrices each have 12,288 columns matching the embedding dimension', 'start': 969.24, 'end': 975.24}, {'text': 'and 128 rows matching the dimension of that smaller key query space.', 'start': 975.24, 'end': 980.24}, {'text': 'This gives us an additional 1.5 million or so parameters for each one.', 'start': 980.24, 'end': 984.84}, {'text': \"If you look at that value matrix by contrast, the way I've described things so far would suggest that it's a square matrix that has 12,200,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8 about 150 million added parameters. And to be clear,\", 'start': 984.84, 'end': 1006.32}, {'text': 'you could do that. You could devote orders of magnitude more parameters to the value map than to the', 'start': 1006.32, 'end': 1010.96}, {'text': 'key in query. But in practice, it is much more efficient if instead you make it so that the number', 'start': 1010.96, 'end': 1015.84}, {'text': 'of parameters devoted to this value map is the same as the number devoted to the key in the query.', 'start': 1015.84, 'end': 1021.2}, {'text': 'This is especially relevant in the setting of running multiple attention heads in parallel.', 'start': 1021.2, 'end': 1026.2}, {'text': 'The way this looks is that the value map is factored as a product of two smaller matrices.', 'start': 1026.2, 'end': 1031.08}, {'text': 'Conceptually, I would still encourage you to think about the overall linear map, one with', 'start': 1031.08, 'end': 1035.08}, {'text': 'inputs and outputs, both in this larger embedding space, for example taking the embedding', 'start': 1035.08, 'end': 1039.68}, {'text': \"of blue to this blueness direction that you would add to nouns. It's just that it's\", 'start': 1039.68, 'end': 1044.44}, {'text': 'broken up into two separate steps.', 'start': 1044.44, 'end': 1047.0}, {'text': 'The first matrix on the right here has a smaller number of rows,', 'start': 1047.0, 'end': 1050.0}, {'text': 'typically the same size as the key query space,', 'start': 1050.0, 'end': 1053.0}, {'text': 'what this means is you can think of it as mapping the large embedding vectors', 'start': 1053.0, 'end': 1057.0}, {'text': 'down to a much smaller space.', 'start': 1057.0, 'end': 1059.0}, {'text': \"This is not the conventional naming, but I'm going to call this the value down matrix.\", 'start': 1059.0, 'end': 1063.0}, {'text': 'The second matrix maps from the smaller space back up to the embedding space, producing the vectors that you use to make the actual updates.', 'start': 1063.0, 'end': 1070.0}, {'text': \"I'm going to call this one the value up matrix, which, again, is not conventional.\", 'start': 1070.0, 'end': 1075.0}, {'text': 'The way that you would see this written in most papers looks a little different.', 'start': 1075.0, 'end': 1078.0}, {'text': \"I'll talk about it in a minute, in my opinion, it tends to make things a little more conceptually confusing.\", 'start': 1078.0, 'end': 1083.0}, {'text': 'To throw in linear algebra jargon here,', 'start': 1083.0, 'end': 1085.26}, {'text': \"what we're basically doing is constraining the overall value map\", 'start': 1085.26, 'end': 1088.48}, {'text': 'to be a low-rank transformation.', 'start': 1088.48, 'end': 1091.36}, {'text': 'Turning back to the parameter count,', 'start': 1091.36, 'end': 1092.96}, {'text': 'all four of these matrices have the same size,', 'start': 1092.96, 'end': 1095.76}, {'text': 'and adding them all up, we get about 6.3 million parameters', 'start': 1095.76, 'end': 1099.56}, {'text': 'for one attention head.', 'start': 1099.56, 'end': 1100.96}, {'text': 'As a quick side note, to be a little more accurate,', 'start': 1102.04, 'end': 1104.04}, {'text': 'everything described so far is what', 'start': 1104.04, 'end': 1105.4}, {'text': 'people would call a self-attention head, to distinguish it from a variation that comes', 'start': 1105.4, 'end': 1109.36}, {'text': \"up in other models that's called cross-attention.\", 'start': 1109.36, 'end': 1112.44}, {'text': \"This isn't relevant to our GPT example, but if you're curious, cross-attention involves\", 'start': 1112.44, 'end': 1116.72}, {'text': 'models that process two distinct types of data, like text in one language and text in', 'start': 1116.72, 'end': 1121.96}, {'text': \"another language that's part of an ongoing generation of a translation, or maybe audio input of speech and an ongoing transcription.\", 'start': 1121.96, 'end': 1130.44}, {'text': 'A cross-attention head looks almost identical.', 'start': 1130.44, 'end': 1133.0}, {'text': 'The only difference is that the key and query maps act on different datasets.', 'start': 1133.0, 'end': 1137.8}, {'text': 'In a model-doing translation, for example, the keys might come from one language, while', 'start': 1137.8, 'end': 1142.24}, {'text': 'the queries come from another, and the attention pattern, could describe which words from one language correspond to which words in another.', 'start': 1142.24, 'end': 1149.52}, {'text': \"And in this setting, there would typically be no masking, since there's not really any notion\", 'start': 1150.16, 'end': 1154.0}, {'text': 'of later tokens affecting earlier ones. Staying focused on self-attention, though, if you', 'start': 1154.0, 'end': 1159.36}, {'text': 'understood everything so far, and if you were to stop here, you would come away with the essence', 'start': 1159.36, 'end': 1163.44}, {'text': 'of what attention really is.', 'start': 1163.44, 'end': 1165.88}, {'text': \"All that's really left to us is to lay out the sense in which you do this many many\", 'start': 1165.88, 'end': 1170.44}, {'text': 'different times.', 'start': 1170.44, 'end': 1172.2}, {'text': 'In our central example, we focused on adjectives updating nouns, but of course there', 'start': 1172.2, 'end': 1176.28}, {'text': 'were lots of different ways that context can influence the meaning of a word.', 'start': 1176.28, 'end': 1180.4}, {'text': 'If the words, they crashed the, preceded the word, car, it has implications for the shape and the structure of that car.', 'start': 1180.4, 'end': 1187.0}, {'text': 'And a lot of associations might be less grammatical.', 'start': 1187.0, 'end': 1189.68}, {'text': 'If the word wizard is anywhere in the same passage as Harry, it suggests that this might be referring to Harry Potter.', 'start': 1189.68, 'end': 1196.24}, {'text': 'Whereas if instead, the words queen, Sussex, and William were in that passage, then perhaps the embedding of Harry should instead be updated to refer to the prints.', 'start': 1196.24, 'end': 1205.04}, {'text': 'For every different type of contextual updating that you might imagine, the parameters', 'start': 1205.04, 'end': 1209.28}, {'text': 'of these key inquiry matrices would be different to capture the different attention patterns,', 'start': 1209.28, 'end': 1213.92}, {'text': 'and the parameters of our value map would be different based on what should be added to the embeddings.', 'start': 1213.92, 'end': 1219.52}, {'text': 'And again, in practice, the true behavior of these maps is much more difficult to interpret,', 'start': 1219.52, 'end': 1224.56}, {'text': 'where the weights are set to do whatever the model needs them to do to best accomplish its', 'start': 1224.56, 'end': 1228.36}, {'text': 'goal of predicting the next token.', 'start': 1228.36, 'end': 1231.44}, {'text': 'As I said before, everything were described as a single head of attention, and a full', 'start': 1231.44, 'end': 1235.56}, {'text': \"attention block inside a transformer consists of what's called multi-headed attention, where\", 'start': 1235.56, 'end': 1240.44}, {'text': 'you run a lot of these operations in parallel, each with its own distinct key query and', 'start': 1240.44, 'end': 1244.96}, {'text': 'value maps.', 'start': 1244.96, 'end': 1246.0}, {'text': 'GPT-3, for example, uses 96 attention heads inside each block.', 'start': 1247.0, 'end': 1252.0}, {'text': \"Considering that each one is already a bit confusing, it's certainly a lot to hold in your head.\", 'start': 1252.0, 'end': 1257.0}, {'text': 'Just to spell it all out very explicitly, this means you have 96 distinct key and query matrices,', 'start': 1257.0, 'end': 1262.0}, {'text': 'producing 96 distinct attention patterns.', 'start': 1262.0, 'end': 1265.44}, {'text': 'Then each head has its own distinct value matrices, used to produce 96 sequences of', 'start': 1265.44, 'end': 1271.24}, {'text': 'value vectors.', 'start': 1271.24, 'end': 1272.8}, {'text': 'These are all added together using the corresponding attention patterns as weights.', 'start': 1272.8, 'end': 1277.52}, {'text': 'What this means is that for each position in the context, each token, every one of these', 'start': 1277.52, 'end': 1282.44}, {'text': 'heads produces a proposed change to be added to the', 'start': 1282.44, 'end': 1285.76}, {'text': 'embedding in that position. So what you do is you sum together all of those proposed changes,', 'start': 1285.76, 'end': 1291.28}, {'text': 'one for each head, and you add the result to the original embedding of that position.', 'start': 1291.28, 'end': 1295.36}, {'text': \"This entire sum here would be one slice of what's outputted from this multi-headed attention block,\", 'start': 1296.48, 'end': 1303.28}, {'text': 'a single one of those refined embeddings', 'start': 1303.28, 'end': 1305.96}, {'text': 'that pops out the other end of it.', 'start': 1305.96, 'end': 1308.24}, {'text': 'Again, this is a lot to think about,', 'start': 1308.24, 'end': 1309.84}, {'text': \"so don't worry at all if it takes some time to sink in.\", 'start': 1309.84, 'end': 1312.48}, {'text': 'The overall idea is that by running many distinct heads', 'start': 1312.48, 'end': 1315.2}, {'text': \"in parallel, you're giving the model the capacity\", 'start': 1315.2, 'end': 1318.28}, {'text': 'to learn many distinct ways that context changes meaning.', 'start': 1318.28, 'end': 1321.96}, {'text': 'Pulling up our running tally for parameter count,', 'start': 1323.64, 'end': 1325.96}, {'text': 'with 96 heads, each including its own variation of these four matrices,', 'start': 1325.96, 'end': 1330.2}, {'text': 'each block of multi-headed attention', 'start': 1330.2, 'end': 1332.48}, {'text': 'ends up with around 600 million parameters.', 'start': 1332.48, 'end': 1335.24}, {'text': \"There's one added slightly annoying thing that I should really mention\", 'start': 1336.24, 'end': 1339.2}, {'text': 'for any of you who go on to read more about transformers.', 'start': 1339.2, 'end': 1342.04}, {'text': 'You remember how I said that the value map is factored out', 'start': 1342.04, 'end': 1344.68}, {'text': 'into these two distinct matrices, which I labeled as the value down and the value', 'start': 1344.68, 'end': 1348.52}, {'text': 'up matrices.', 'start': 1348.52, 'end': 1349.88}, {'text': 'The way that I framed things would suggest that you see this pair of matrices inside', 'start': 1349.88, 'end': 1354.6}, {'text': 'each attention head, and you could absolutely implement it this way, that would be a', 'start': 1354.6, 'end': 1359.16}, {'text': 'valid design.', 'start': 1359.16, 'end': 1360.36}, {'text': \"But the way that you see this written in papers and the way that it's implemented in practice\", 'start': 1360.36, 'end': 1363.96}, {'text': 'looks a little different. All of these value up matrices for each head appear stapled together', 'start': 1363.96, 'end': 1370.0}, {'text': 'in one giant matrix that we call the output matrix, associated with the entire multi-headed', 'start': 1370.0, 'end': 1375.44}, {'text': 'attention block. And when you see people refer to the value matrix for a given attention head,', 'start': 1375.44, 'end': 1380.08}, {'text': \"they're typically only referring to this first step, the one that I was labeling as the value down, projection into the smaller space.\", 'start': 1380.08, 'end': 1387.0}, {'text': \"For the curious among you, I've left an on-screen note about it.\", 'start': 1388.0, 'end': 1391.0}, {'text': \"It's one of those details that runs the risk of distracting from the main conceptual points,\", 'start': 1391.0, 'end': 1395.0}, {'text': 'but I do want to call it out just so that you know if you read about this in other sources.', 'start': 1395.0, 'end': 1399.0}, {'text': 'Setting aside all the technical nuances in the preview from the last chapter,', 'start': 1399.0, 'end': 1403.0}, {'text': \"we saw how data flowing through a transformer doesn't just flow through a single attention block. For one thing, it also goes through\", 'start': 1403.0, 'end': 1409.84}, {'text': \"these other operations called multilayer perceptrons, we'll talk more about those in the next chapter,\", 'start': 1409.84, 'end': 1414.88}, {'text': 'and then it repeatedly goes through many many copies of both of these operations. What this means', 'start': 1414.88, 'end': 1420.64}, {'text': 'is that after a given word imbibes some of its context, there are many more chances', 'start': 1420.64, 'end': 1425.8}, {'text': 'for this more nuanced embedding to be influenced by its more nuanced surroundings.', 'start': 1425.8, 'end': 1430.88}, {'text': 'The further down the network you go, with each embedding, taking in more and more meaning', 'start': 1430.88, 'end': 1435.12}, {'text': 'from all the other embeddings, which themselves are getting more and more nuanced,', 'start': 1435.12, 'end': 1439.12}, {'text': \"the hope is that there's the capacity to encode higher level and more abstract ideas about\", 'start': 1439.12, 'end': 1443.64}, {'text': 'a given input beyond just', 'start': 1443.64, 'end': 1445.32}, {'text': \"descriptors and grammatical structure. Things like sentiment and tone and whether it's a poem\", 'start': 1445.32, 'end': 1451.04}, {'text': 'and what underlying scientific truths are relevant to the piece and things like that.', 'start': 1451.04, 'end': 1456.72}, {'text': 'Turning back one more time to our scorekeeping, GPT-3 includes 96 distinct layers, so the', 'start': 1456.72, 'end': 1462.84}, {'text': 'total number of key query and value parameters is multiplied', 'start': 1462.84, 'end': 1466.4}, {'text': 'by another 96, which brings the total sum to just under 58 billion distinct parameters devoted', 'start': 1466.4, 'end': 1473.08}, {'text': 'to all of the attention heads.', 'start': 1473.08, 'end': 1475.08}, {'text': \"That is a lot to be sure, but it's only about a third of the 175 billion that are in\", 'start': 1475.08, 'end': 1479.92}, {'text': 'the network in total.', 'start': 1479.92, 'end': 1481.6}, {'text': 'So even though attention gets all of the attention, the majority of parameters', 'start': 1481.6, 'end': 1485.52}, {'text': 'come from the blocks sitting in between these steps. In the next chapter, you and I will talk', 'start': 1485.52, 'end': 1489.92}, {'text': 'more about those other blocks and also a lot more about the training process. A big part of the', 'start': 1489.92, 'end': 1494.64}, {'text': 'story for the success of the attention mechanism is not so much any specific kind of behavior', 'start': 1494.64, 'end': 1499.92}, {'text': \"that enables, but the fact that it's extremely parallelizable, meaning that you can run a huge number of computations in a short time using GPUs.\", 'start': 1499.92, 'end': 1509.36}, {'text': 'Given that one of the big lessons about deep learning in the last decade or two has', 'start': 1509.36, 'end': 1512.68}, {'text': 'been that scale alone seems to give huge qualitative improvements in model performance,', 'start': 1512.68, 'end': 1517.52}, {'text': \"there's a huge advantage to parallelizable architectures that let you do this.\", 'start': 1517.52, 'end': 1522.16}, {'text': \"If you want to learn more about this stuff, I've left lots of links in the description.\", 'start': 1522.16, 'end': 1525.68}, {'text': 'In particular, anything produced by Andre Carpathia, Chris Ola, tend to be pure gold.', 'start': 1525.68, 'end': 1530.4}, {'text': 'In this video, I wanted to just jump into attention in its current form,', 'start': 1530.4, 'end': 1533.84}, {'text': \"but if you're curious about more of the history for how we got here and how you might reinvent\", 'start': 1533.84, 'end': 1537.52}, {'text': 'this idea for yourself, my friend Vivek just put up a couple videos, giving a lot more of that', 'start': 1537.52, 'end': 1541.76}, {'text': 'motivation. Also, Britt Cruz from the channel The art of the problem has a really nice video about the history of large language models.', 'start': 1541.76, 'end': 1548.48}, {'text': 'you', 'start': 1564.17, 'end': 1566.17}]\n"
     ]
    }
   ],
   "source": [
    "def convert_transcript_to_json(transcript):\n",
    "    return [\n",
    "            {\n",
    "                \"text\": chunk['text'].strip(),\n",
    "                \"start\": chunk['timestamp'][0],\n",
    "                \"end\": chunk['timestamp'][1]\n",
    "            }\n",
    "            for chunk in transcript['chunks']\n",
    "        ]\n",
    "    processed_chunks = [f\"{i}: {chunk['text']}\" for i, chunk in enumerate(transcript['chunks'], start=1)]\n",
    "    return \"\\n\".join(processed_chunks)\n",
    "\n",
    "processed_transcript = convert_transcript_to_json(text)\n",
    "print(processed_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video files in 'data' directory: [PosixPath('data/IMG_1406.MOV'), PosixPath('data/IMG_1407.MOV'), PosixPath('data/IMG_1411.MOV'), PosixPath('data/IMG_1405.MOV'), PosixPath('data/IMG_1404.MOV'), PosixPath('data/IMG_1410.MOV'), PosixPath('data/IMG_1399.MOV'), PosixPath('data/IMG_1414.MOV'), PosixPath('data/IMG_1400.MOV'), PosixPath('data/IMG_1415.MOV'), PosixPath('data/IMG_1398.MOV'), PosixPath('data/IMG_1417.MOV'), PosixPath('data/IMG_1416.MOV'), PosixPath('data/IMG_1444.MOV'), PosixPath('data/IMG_1446.MOV'), PosixPath('data/IMG_1442.MOV'), PosixPath('data/IMG_1441.MOV'), PosixPath('data/IMG_1382.MOV'), PosixPath('data/IMG_1396.MOV'), PosixPath('data/IMG_1427.MOV'), PosixPath('data/IMG_1432.MOV'), PosixPath('data/IMG_1426.MOV'), PosixPath('data/IMG_1397.MOV'), PosixPath('data/IMG_1383.MOV'), PosixPath('data/IMG_1381.MOV'), PosixPath('data/IMG_1418.MOV'), PosixPath('data/IMG_1419.MOV'), PosixPath('data/IMG_1425.MOV'), PosixPath('data/IMG_1431.MOV'), PosixPath('data/IMG_1384.MOV'), PosixPath('data/IMG_1409.MOV'), PosixPath('data/IMG_1408.MOV'), PosixPath('data/IMG_1437.MOV')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_video_files(data_directory):\n",
    "    video_files = [file for file in data_directory.glob('*') if file.suffix.lower() in ['.mp4', '.mov', '.avi', '.mkv']]\n",
    "    return video_files\n",
    "\n",
    "data_directory = Path('data')\n",
    "video_files = get_video_files(data_directory)\n",
    "print(\"Video files in 'data' directory:\", video_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1406.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:46:03.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.744107\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1297.182/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:46:03-0600\n",
      "  Duration: 00:00:13.80, start: 0.000000, bitrate: 55256 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 54960 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:46:03.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 178 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:46:03.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:46:03.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:46:03.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 79 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:46:03.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1406.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:46:03-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.744107\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1297.182/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:46:03.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x14cf40560] video:0kB audio:216kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.314196%\n",
      "size=     217kB time=00:00:13.79 bitrate= 128.9kbits/s speed=83.4x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1407.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:56:02.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.617584\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0533+1298.573/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:56:02-0600\n",
      "  Duration: 00:00:10.87, start: 0.000000, bitrate: 9234 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 1920x1080, 8967 kb/s, 30 fps, 30 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:02.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 4, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 192 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:02.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:02.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 18 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:02.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 40 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:02.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1407.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:56:02-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.617584\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0533+1298.573/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:02.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x143e063b0] video:0kB audio:170kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.399337%\n",
      "size=     171kB time=00:00:10.84 bitrate= 129.1kbits/s speed=78.2x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1411.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:58:40.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.762936\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1301.244/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:58:40-0600\n",
      "  Duration: 00:00:32.17, start: 0.000000, bitrate: 29924 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 29673 kb/s, 30 fps, 30 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:58:40.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 7, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 192 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:58:40.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:58:40.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 1 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:58:40.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 37 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:58:40.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1411.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:58:40-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.762936\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1301.244/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:58:40.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x129912760] video:0kB audio:503kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.135056%\n",
      "size=     504kB time=00:00:32.15 bitrate= 128.4kbits/s speed=82.4x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1405.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:45:35.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.752842\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1298.680/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:45:35-0600\n",
      "  Duration: 00:00:21.27, start: 0.000000, bitrate: 55140 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 54838 kb/s, 60 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:45:35.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 198 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:45:35.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:45:35.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:45:35.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 75 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:45:35.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1405.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:45:35-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.752842\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1298.680/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:45:35.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x12cf25330] video:0kB audio:333kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.204073%\n",
      "size=     334kB time=00:00:21.26 bitrate= 128.6kbits/s speed=79.5x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1404.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:44:49.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.760774\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1298.666/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:44:49-0600\n",
      "  Duration: 00:00:26.30, start: 0.000000, bitrate: 54815 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 54494 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:44:49.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 200 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:44:49.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:44:49.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 7 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:44:49.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 82 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:44:49.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1404.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:44:49-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.760774\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1298.666/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:44:49.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x152f044c0] video:0kB audio:412kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.165038%\n",
      "size=     413kB time=00:00:26.30 bitrate= 128.5kbits/s speed=  82x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1410.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:57:48.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.761704\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1299.543/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:57:48-0600\n",
      "  Duration: 00:00:05.90, start: 0.000000, bitrate: 9253 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 1920x1080, 9017 kb/s, 30 fps, 30 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:48.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 4, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 181 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:48.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:48.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:48.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 34 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:48.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1410.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:57:48-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.761704\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1299.543/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:48.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x10bf064c0] video:0kB audio:93kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.730371%\n",
      "size=      94kB time=00:00:05.90 bitrate= 130.1kbits/s speed=84.5x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1399.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:40:16.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.758074\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1297.644/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:40:16-0600\n",
      "  Duration: 00:00:43.29, start: 0.000000, bitrate: 54160 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53848 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:40:16.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 209 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:40:16.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:40:16.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:40:16.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 76 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:40:16.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1399.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:40:16-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.758074\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1297.644/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:40:16.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x12d807250] video:0kB audio:677kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.100376%\n",
      "size=     678kB time=00:00:43.28 bitrate= 128.3kbits/s speed=77.5x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1414.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:59:48.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.747184\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1299.529/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:59:48-0600\n",
      "  Duration: 00:01:45.58, start: 0.000000, bitrate: 53700 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53383 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:59:48.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 198 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:59:48.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D) (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:59:48.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 6 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:59:48.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 87 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:59:48.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1414.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:59:48-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.747184\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1299.529/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:59:48.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x12c62db90] video:0kB audio:1650kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.041188%\n",
      "size=    1651kB time=00:01:45.56 bitrate= 128.1kbits/s speed=83.3x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1400.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:41:55.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.767583\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1299.489/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:41:55-0600\n",
      "  Duration: 00:00:05.23, start: 0.000000, bitrate: 59050 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 58758 kb/s, 60 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:41:55.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 184 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:41:55.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:41:55.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:41:55.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 84 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:41:55.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1400.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:41:55-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.767583\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1299.489/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:41:55.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x158648160] video:0kB audio:82kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.824381%\n",
      "size=      83kB time=00:00:05.22 bitrate= 130.3kbits/s speed=81.3x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1415.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:01:44.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 15.140076\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0534+1298.996/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:01:44-0600\n",
      "  Duration: 00:00:40.70, start: 0.000000, bitrate: 53998 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53698 kb/s, 60 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:01:44.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 196 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:01:44.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:01:44.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:01:44.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 78 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:01:44.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1415.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:01:44-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 15.140076\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0534+1298.996/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:01:44.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x11c62a4e0] video:0kB audio:637kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.106831%\n",
      "size=     638kB time=00:00:40.72 bitrate= 128.3kbits/s speed=88.4x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1398.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:38:07.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.743315\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1299.443/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:38:07-0600\n",
      "  Duration: 00:00:46.40, start: 0.000000, bitrate: 54131 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53807 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:38:07.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 198 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:38:07.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:38:07.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 9 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:38:07.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 88 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:38:07.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1398.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:38:07-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.743315\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1299.443/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:38:07.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x141e40da0] video:0kB audio:726kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.093658%\n",
      "size=     726kB time=00:00:46.39 bitrate= 128.3kbits/s speed=80.3x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1417.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:05:10.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.754071\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1301.342/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:05:10-0600\n",
      "  Duration: 00:00:36.25, start: 0.000000, bitrate: 54267 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53937 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:05:10.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 190 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:05:10.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:05:10.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 16 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:05:10.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 94 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:05:10.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1417.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:05:10-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.754071\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1301.342/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:05:10.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x128648400] video:0kB audio:567kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.119801%\n",
      "size=     568kB time=00:00:36.25 bitrate= 128.3kbits/s speed=77.9x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1416.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:02:50.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.613194\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1299.358/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:02:50-0600\n",
      "  Duration: 00:01:03.39, start: 0.000000, bitrate: 53966 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53674 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:02:50.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 195 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:02:50.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:02:50.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:02:50.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 70 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:02:50.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1416.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:02:50-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.613194\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1299.358/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:02:50.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x136106ea0] video:0kB audio:991kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.068585%\n",
      "size=     992kB time=00:01:03.37 bitrate= 128.2kbits/s speed=86.1x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1444.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:40:50.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.768257\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0534+1299.054/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:40:49-0600\n",
      "  Duration: 00:00:30.54, start: 0.000000, bitrate: 54120 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53786 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:50.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 184 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:50.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:50.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 22 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:50.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 99 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:50.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1444.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:40:49-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.768257\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0534+1299.054/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:50.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x123f1cf40] video:0kB audio:478kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.142206%\n",
      "size=     479kB time=00:00:30.53 bitrate= 128.4kbits/s speed=  83x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1446.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:41:56.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.769332\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0533+1297.807/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:41:56-0600\n",
      "  Duration: 00:00:04.28, start: 0.000000, bitrate: 54055 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53763 kb/s, 60 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:41:56.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 196 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:41:56.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:41:56.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:41:56.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 69 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:41:56.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1446.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:41:56-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.769332\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0533+1297.807/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:41:56.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x14c104080] video:0kB audio:68kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.003156%\n",
      "size=      68kB time=00:00:04.28 bitrate= 130.8kbits/s speed=82.3x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1442.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:40:30.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.767799\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0533+1299.871/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:40:30-0600\n",
      "  Duration: 00:00:15.05, start: 0.000000, bitrate: 54254 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53927 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:30.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 184 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:30.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:30.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 15 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:30.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 94 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:30.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1442.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:40:30-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.767799\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0533+1299.871/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:30.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x132e483a0] video:0kB audio:236kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.288103%\n",
      "size=     237kB time=00:00:15.04 bitrate= 128.8kbits/s speed=  83x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1441.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:40:09.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.767918\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0534+1299.530/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:40:09-0600\n",
      "  Duration: 00:00:19.75, start: 0.000000, bitrate: 52700 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 52373 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:09.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 194 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:09.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:09.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 10 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:09.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 91 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:09.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1441.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:40:09-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.767918\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0534+1299.530/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:40:09.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x14162d910] video:0kB audio:309kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.219688%\n",
      "size=     310kB time=00:00:19.74 bitrate= 128.6kbits/s speed=79.1x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1382.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:28:24.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.743432\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1299.390/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:28:24-0600\n",
      "  Duration: 00:00:49.60, start: 0.000000, bitrate: 54138 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53807 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:28:24.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 189 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:28:24.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:28:24.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 17 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:28:24.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 95 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:28:24.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1382.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:28:24-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.743432\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1299.390/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:28:24.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x12a8045d0] video:0kB audio:776kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.087598%\n",
      "size=     777kB time=00:00:49.60 bitrate= 128.2kbits/s speed=83.4x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1396.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:33:34.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745339\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1298.950/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:33:34-0600\n",
      "  Duration: 00:00:03.78, start: 0.000000, bitrate: 56390 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 56056 kb/s, 60 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:33:34.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 210 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:33:34.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:33:34.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:33:34.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 69 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:33:34.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1396.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:33:34-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745339\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1298.950/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:33:34.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x143007140] video:0kB audio:60kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.140572%\n",
      "size=      60kB time=00:00:03.76 bitrate= 131.2kbits/s speed=78.9x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1427.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:15:34.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.743724\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0534+1298.806/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:15:34-0600\n",
      "  Duration: 00:00:12.29, start: 0.000000, bitrate: 55023 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 54718 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:15:34.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 202 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:15:34.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:15:34.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:15:34.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 69 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:15:34.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1427.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:15:34-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.743724\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0534+1298.806/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:15:34.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x110608990] video:0kB audio:193kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.352059%\n",
      "size=     194kB time=00:00:12.30 bitrate= 129.0kbits/s speed=78.7x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1432.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:26:33.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745184\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0531+1299.223/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:26:33-0600\n",
      "  Duration: 00:00:19.42, start: 0.000000, bitrate: 53854 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53541 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:26:33.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 206 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:26:33.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:26:33.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:26:33.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 77 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:26:33.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1432.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:26:33-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745184\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0531+1299.223/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:26:33.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x132606c50] video:0kB audio:304kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.223522%\n",
      "size=     305kB time=00:00:19.41 bitrate= 128.6kbits/s speed=80.9x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1426.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:14:59.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745269\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0532+1303.094/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:14:59-0600\n",
      "  Duration: 00:00:15.64, start: 0.000000, bitrate: 54868 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 54577 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:59.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 191 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:59.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:59.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:59.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 69 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:59.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1426.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:14:59-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745269\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0532+1303.094/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:59.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x130722fa0] video:0kB audio:245kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.277078%\n",
      "size=     246kB time=00:00:15.64 bitrate= 128.8kbits/s speed=83.5x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1397.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:35:32.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745703\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1296.301/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:35:32-0600\n",
      "  Duration: 00:00:10.10, start: 0.000000, bitrate: 57006 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 56708 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:35:32.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 203 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:35:32.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:35:32.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:35:32.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 69 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:35:32.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1397.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:35:32-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745703\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1296.301/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:35:32.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x139726420] video:0kB audio:159kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.428081%\n",
      "size=     159kB time=00:00:10.11 bitrate= 129.2kbits/s speed=77.9x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1383.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:29:50.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.744054\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1297.630/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:29:50-0600\n",
      "  Duration: 00:00:12.03, start: 0.000000, bitrate: 56280 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 55949 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:29:50.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 204 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:29:50.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:29:50.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 2 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:29:50.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 83 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:29:50.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1383.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:29:50-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.744054\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1297.630/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:29:50.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x1580067f0] video:0kB audio:189kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.359662%\n",
      "size=     190kB time=00:00:12.04 bitrate= 129.0kbits/s speed=75.1x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1381.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:24:30.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.764406\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1299.692/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:24:30-0600\n",
      "  Duration: 00:01:00.82, start: 0.000000, bitrate: 53295 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 52966 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:24:30.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 186 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:24:30.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:24:30.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 18 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:24:30.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 96 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:24:30.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1381.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:24:30-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.764406\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1299.692/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:24:30.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x145b04890] video:0kB audio:951kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.071469%\n",
      "size=     952kB time=00:01:00.81 bitrate= 128.2kbits/s speed=85.1x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1418.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:06:29.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.763428\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1298.269/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:06:29-0600\n",
      "  Duration: 00:00:06.32, start: 0.000000, bitrate: 55556 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 55262 kb/s, 60 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:06:29.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 203 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:06:29.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:06:29.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:06:29.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 69 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:06:29.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1418.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:06:29-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.763428\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1298.269/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:06:29.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x1431126a0] video:0kB audio:100kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.682473%\n",
      "size=     100kB time=00:00:06.32 bitrate= 129.9kbits/s speed=80.5x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1419.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:07:47.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745182\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0534+1298.684/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:07:47-0600\n",
      "  Duration: 00:00:35.69, start: 0.000000, bitrate: 53813 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53466 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:07:47.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 211 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:07:47.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:07:47.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 16 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:07:47.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 91 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:07:47.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1419.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:07:47-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745182\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0534+1298.684/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:07:47.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x13b606400] video:0kB audio:558kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.121728%\n",
      "size=     559kB time=00:00:35.68 bitrate= 128.3kbits/s speed=76.7x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1425.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:14:33.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745235\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1304.018/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:14:33-0600\n",
      "  Duration: 00:00:24.47, start: 0.000000, bitrate: 54286 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 53980 kb/s, 60 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:33.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 196 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:33.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:33.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 3 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:33.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 78 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:33.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1425.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:14:33-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.745235\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1304.018/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:14:33.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x140632da0] video:0kB audio:383kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.177531%\n",
      "size=     384kB time=00:00:24.45 bitrate= 128.5kbits/s speed=76.2x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1431.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:23:42.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.761320\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1300.467/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:23:42-0600\n",
      "  Duration: 00:00:09.62, start: 0.000000, bitrate: 58651 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 58349 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:23:42.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 200 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:23:42.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:23:42.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:23:42.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 71 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:23:42.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1431.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:23:42-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.761320\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0532+1300.467/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:23:42.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x150706510] video:0kB audio:151kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.450066%\n",
      "size=     152kB time=00:00:09.61 bitrate= 129.3kbits/s speed=68.8x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1384.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:30:19.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.743591\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1299.619/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:30:18-0600\n",
      "  Duration: 00:00:19.64, start: 0.000000, bitrate: 54449 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 3840x2160, 54136 kb/s, 59.99 fps, 60 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:30:19.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 10, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 193 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:30:19.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:30:19.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 3 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:30:19.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 86 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:30:19.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1384.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:30:18-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.743591\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1299.619/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:30:19.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x15710aba0] video:0kB audio:307kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.221147%\n",
      "size=     308kB time=00:00:19.61 bitrate= 128.6kbits/s speed=79.5x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1409.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:57:21.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.754903\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0533+1297.661/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:57:20-0600\n",
      "  Duration: 00:00:10.93, start: 0.000000, bitrate: 9566 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 1920x1080, 9282 kb/s, 30 fps, 30 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:21.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 4, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 209 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:21.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:21.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 18 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:21.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 40 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:21.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1409.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:57:20-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.754903\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0533+1297.661/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:57:21.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x121604080] video:0kB audio:171kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.396486%\n",
      "size=     172kB time=00:00:10.92 bitrate= 129.1kbits/s speed=72.4x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1408.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T21:56:44.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.765935\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1300.137/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:56:44-0600\n",
      "  Duration: 00:00:20.30, start: 0.000000, bitrate: 10173 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 1920x1080, 9921 kb/s, 30 fps, 30 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:44.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 4, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 192 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:44.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:44.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 4 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:44.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 36 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:44.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1408.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T15:56:44-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 4.765935\n",
      "    com.apple.quicktime.location.ISO6709: +41.0705-112.0535+1300.137/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T21:56:44.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "[out#0/mp3 @ 0x13a106b70] video:0kB audio:318kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.213766%\n",
      "size=     319kB time=00:00:20.29 bitrate= 128.6kbits/s speed=65.9x    \n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/IMG_1437.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-03-12T22:33:21.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 6.171213\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0531+1298.557/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:33:21-0600\n",
      "  Duration: 00:00:28.87, start: 0.000000, bitrate: 11297 kb/s\n",
      "  Stream #0:0[0x1](und): Video: hevc (Main 10) (hvc1 / 0x31637668), yuv420p10le(tv, bt2020nc/bt2020/arib-std-b67), 1920x1080, 11052 kb/s, 30 fps, 30 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:33:21.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : HEVC\n",
      "    Side data:\n",
      "      DOVI configuration record: version: 1.0, profile: 8, level: 4, rpu flag: 1, el flag: 0, bl flag: 1, compatibility id: 4\n",
      "      displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 195 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:33:21.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:33:21.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:33:21.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 34 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:33:21.000000Z\n",
      "      handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'data/mp3/IMG_1437.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-03-12T16:33:21-0600\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 6.171213\n",
      "    com.apple.quicktime.location.ISO6709: +41.0704-112.0531+1298.557/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone 14 Pro\n",
      "    com.apple.quicktime.software: 17.3.1\n",
      "    TSSE            : Lavf60.16.100\n",
      "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-03-12T22:33:21.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 libmp3lame\n",
      "size=       0kB time=N/A bitrate=N/A speed=N/A    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted MP3 files: [PosixPath('data/mp3/IMG_1406.mp3'), PosixPath('data/mp3/IMG_1407.mp3'), PosixPath('data/mp3/IMG_1411.mp3'), PosixPath('data/mp3/IMG_1405.mp3'), PosixPath('data/mp3/IMG_1404.mp3'), PosixPath('data/mp3/IMG_1410.mp3'), PosixPath('data/mp3/IMG_1399.mp3'), PosixPath('data/mp3/IMG_1414.mp3'), PosixPath('data/mp3/IMG_1400.mp3'), PosixPath('data/mp3/IMG_1415.mp3'), PosixPath('data/mp3/IMG_1398.mp3'), PosixPath('data/mp3/IMG_1417.mp3'), PosixPath('data/mp3/IMG_1416.mp3'), PosixPath('data/mp3/IMG_1444.mp3'), PosixPath('data/mp3/IMG_1446.mp3'), PosixPath('data/mp3/IMG_1442.mp3'), PosixPath('data/mp3/IMG_1441.mp3'), PosixPath('data/mp3/IMG_1382.mp3'), PosixPath('data/mp3/IMG_1396.mp3'), PosixPath('data/mp3/IMG_1427.mp3'), PosixPath('data/mp3/IMG_1432.mp3'), PosixPath('data/mp3/IMG_1426.mp3'), PosixPath('data/mp3/IMG_1397.mp3'), PosixPath('data/mp3/IMG_1383.mp3'), PosixPath('data/mp3/IMG_1381.mp3'), PosixPath('data/mp3/IMG_1418.mp3'), PosixPath('data/mp3/IMG_1419.mp3'), PosixPath('data/mp3/IMG_1425.mp3'), PosixPath('data/mp3/IMG_1431.mp3'), PosixPath('data/mp3/IMG_1384.mp3'), PosixPath('data/mp3/IMG_1409.mp3'), PosixPath('data/mp3/IMG_1408.mp3'), PosixPath('data/mp3/IMG_1437.mp3')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/mp3 @ 0x125e49f40] video:0kB audio:452kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.150428%\n",
      "size=     453kB time=00:00:28.86 bitrate= 128.4kbits/s speed=73.5x    \n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Function to extract mp3 from mp4\n",
    "def extract_mp3_from_video(mp4_file_path, output_directory):\n",
    "    output_mp3_path = output_directory / f\"{mp4_file_path.stem}.mp3\"\n",
    "    command = f\"ffmpeg -i {mp4_file_path} {output_mp3_path}\"\n",
    "    subprocess.run(command, shell=True)\n",
    "    return output_mp3_path\n",
    "\n",
    "# Create a directory for the extracted mp3 files if it doesn't exist\n",
    "mp3_directory = data_directory / 'mp3'\n",
    "mp3_directory.mkdir(exist_ok=True)\n",
    "\n",
    "# Extract mp3 files from each mp4 file\n",
    "extracted_mp3_files = [extract_mp3_from_video(mp4_file, mp3_directory) for mp4_file in video_files]\n",
    "print(\"Extracted MP3 files:\", extracted_mp3_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed files saved with timestamps: [PosixPath('data/transcripts/IMG_1406.json'), PosixPath('data/transcripts/IMG_1407.json'), PosixPath('data/transcripts/IMG_1411.json'), PosixPath('data/transcripts/IMG_1405.json'), PosixPath('data/transcripts/IMG_1404.json'), PosixPath('data/transcripts/IMG_1410.json'), PosixPath('data/transcripts/IMG_1399.json'), PosixPath('data/transcripts/IMG_1414.json'), PosixPath('data/transcripts/IMG_1400.json'), PosixPath('data/transcripts/IMG_1415.json'), PosixPath('data/transcripts/IMG_1398.json'), PosixPath('data/transcripts/IMG_1417.json'), PosixPath('data/transcripts/IMG_1416.json'), PosixPath('data/transcripts/IMG_1444.json'), PosixPath('data/transcripts/IMG_1446.json'), PosixPath('data/transcripts/IMG_1442.json'), PosixPath('data/transcripts/IMG_1441.json'), PosixPath('data/transcripts/IMG_1382.json'), PosixPath('data/transcripts/IMG_1396.json'), PosixPath('data/transcripts/IMG_1427.json'), PosixPath('data/transcripts/IMG_1432.json'), PosixPath('data/transcripts/IMG_1426.json'), PosixPath('data/transcripts/IMG_1397.json'), PosixPath('data/transcripts/IMG_1383.json'), PosixPath('data/transcripts/IMG_1381.json'), PosixPath('data/transcripts/IMG_1418.json'), PosixPath('data/transcripts/IMG_1419.json'), PosixPath('data/transcripts/IMG_1425.json'), PosixPath('data/transcripts/IMG_1431.json'), PosixPath('data/transcripts/IMG_1384.json'), PosixPath('data/transcripts/IMG_1409.json'), PosixPath('data/transcripts/IMG_1408.json'), PosixPath('data/transcripts/IMG_1437.json')]\n"
     ]
    }
   ],
   "source": [
    "# Transcribe each MP3 file using the Whisper pipeline with timestamps and save the transcripts\n",
    "import json\n",
    "\n",
    "def transcribe_and_save(mp3_file_path, output_directory):\n",
    "    transcription_result = pipeline(str(mp3_file_path), return_timestamps=True)\n",
    "    transcript_json = convert_transcript_to_json(transcription_result)\n",
    "    \n",
    "    # Define the output path for the transcript\n",
    "    output_transcript_path = output_directory / f\"{mp3_file_path.stem}.json\"\n",
    "    \n",
    "    # Write the transcription to a file as a JSON object\n",
    "    with open(output_transcript_path, 'w') as file:\n",
    "        json.dump(transcript_json, file)\n",
    "    \n",
    "    return output_transcript_path\n",
    "\n",
    "# Create a directory for the transcripts if it doesn't exist\n",
    "transcript_directory = data_directory / 'transcripts'\n",
    "transcript_directory.mkdir(exist_ok=True)\n",
    "\n",
    "# Transcribe each MP3 file and save the transcripts with timestamps\n",
    "transcribed_files = [transcribe_and_save(mp3_file, transcript_directory) for mp3_file in extracted_mp3_files]\n",
    "print(\"Transcribed files saved with timestamps:\", transcribed_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load OpenAI API key from environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.\")\n",
    "print(\"OpenAI API key loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are producing a storyboard for a video with the following instruction: `make an advertising video`. Your goal is to select sentences from each of the given transcripts to stitch together into a final video.Return a json file with a list of tuples named `segments`, each containing a `video` field with the filename and a `idx` field with the index of the sentence in that video.\n",
      "IMG_1406\n",
      "1: Oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh,\n",
      "\n",
      "IMG_1407\n",
      "1: Let's go.\n",
      "2: See you later.\n",
      "3: Here we go.\n",
      "\n",
      "IMG_1411\n",
      "1: Let's go! See you next time!\n",
      "\n",
      "IMG_1405\n",
      "1: Thank you for watching!\n",
      "2: Thanks.\n",
      "\n",
      "IMG_1404\n",
      "1: I'll be down here looking at you.\n",
      "2: Yep.\n",
      "3: Just one of the advantages of having a clean out box like this is water will flow in and\n",
      "4: you can see it will allow debris to go in the bottom of this box.\n",
      "5: When you take the lid off, you can go down and you can take out the solids with your hand\n",
      "6: and clean it out a couple of times a year and then this will never clog.\n",
      "7: with your hand and clean it out a couple of times a year and then this will never clog.\n",
      "\n",
      "IMG_1410\n",
      "1: See you next time!\n",
      "\n",
      "IMG_1399\n",
      "1: It's time laps on this here.\n",
      "2: All right, I think it's bigger but I was worried about that.\n",
      "3: That's right, it's bigger and it's really good.\n",
      "4: And that's actually why.\n",
      "5: And that's actually why.\n",
      "\n",
      "IMG_1414\n",
      "1: So what I've put on this, that thing.\n",
      "2: What it's doing right now, this is just really working at the clock.\n",
      "3: It's eroding in a way.\n",
      "4: And each time it gets out of it, they're going a little bit further and a little bit further until we can get it.\n",
      "5: It's only on clock here.\n",
      "6: This one's been clocked for a long time.\n",
      "7: We just broke through the floor. Ajojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojojo A-C-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R-E-R- See you next time!\n",
      "\n",
      "IMG_1400\n",
      "1: Alright, it could leave grab it back in my chuck.\n",
      "\n",
      "IMG_1415\n",
      "1: So we got it. We got darts. We had a bad name.\n",
      "2: Pain.\n",
      "3: It's probably my son's.\n",
      "4: This is whatever.\n",
      "5: Who's that? Jeff, I see. this is what I have to do whatever these are\n",
      "6: javics\n",
      "7: and a whole bunch of\n",
      "8: whole bunch of dirt that came with it\n",
      "9: you\n",
      "\n",
      "IMG_1398\n",
      "1: All right, now we got this located.\n",
      "2: We found that where it went into the landscaping.\n",
      "3: This is what we see a lot as a midder.\n",
      "4: This is supposed to pop up when water comes and it'll overflow.\n",
      "5: The problem is this is a 90 degree elbow.\n",
      "6: So if the brale start clogging right here and it'll back up this line,\n",
      "7: it'll ultimately make it so that it can't drain.\n",
      "8: So what were you recommend is to replace this in the middle with a clean out box.\n",
      "9: This will go in here with a cap on it.\n",
      "10: What this allows the homeowner to take this cap off and they can put their hand on in\n",
      "11: there and they can take out any dirt or debris that goes into that box.\n",
      "12: It's much more efficient.\n",
      "13: out any dirt or debris that goes into that box. It's much more efficient.\n",
      "\n",
      "IMG_1417\n",
      "1: Whenever we do this it's fun to see what comes out of these trains.\n",
      "2: Today we found some fireworks, early parts of, badminton, Nerf tips, and then this is all\n",
      "3: the roof granulators that came behind it.\n",
      "4: So if you can imagine something gets on the roof, washes into the rain gutter, washes\n",
      "5: down the downspout, into this drain and it stops at the drain.\n",
      "6: Once all this is at the end then you've got all these\n",
      "7: roof gland granulars that come in behind it and that's why this drain was clogged so bad.\n",
      "8: This one was clogged almost the whole link all the way back to the downspout.\n",
      "\n",
      "IMG_1416\n",
      "1: The next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, the next morning, It's give us some drama. I don't care, yeah. The next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, Oh!\n",
      "\n",
      "IMG_1444\n",
      "1: There are some DIY I are doing it yourself, options out there, people get a jitter and\n",
      "2: put this on the end of a pressure washer.\n",
      "3: And what we found is if the tube is not fully compacted, sometimes that will work to\n",
      "4: get the inner grand drain working, but if it's fully compacted and has been clogged for\n",
      "5: a long time, you have to get a specific machine that's on the jitter, as much higher PSI\n",
      "6: and much more gallons per minute of water flowing through that line\n",
      "7: in order to break the debris that's out of the underground drain.\n",
      "\n",
      "IMG_1446\n",
      "1: See you next time!\n",
      "\n",
      "IMG_1442\n",
      "1: propellant for it.\n",
      "2: Uh, and say in these backgits propellant for\n",
      "3: these three backgits are forcing the front to go forward and erode\n",
      "4: whatever it is that's in its way.\n",
      "\n",
      "IMG_1441\n",
      "1: And go.\n",
      "2: The machine that we use to clean these underground drains\n",
      "3: has a high pressure jetting tip.\n",
      "4: You have a Ford facing jet and three reverse facing jets.\n",
      "5: What that does is the Ford facing jet\n",
      "6: eats away at any roots or debris,\n",
      "7: shingled debris, dirt, that kind of stuff\n",
      "8: in the underground drain.\n",
      "\n",
      "IMG_1382\n",
      "1: We're in a house today that was built in 2003 and have come across a problem that we\n",
      "2: find fairly often.\n",
      "3: When a rain gutter or a downspot comes down off the rain gutter and ties into an underground\n",
      "4: drain that you see here, the underground drain takes it under the sidewalk and out into\n",
      "5: the landscaping somewhere out here.\n",
      "6: I think we'll find the best case scenario in a midter that's in the grass here. We'll locate that. When\n",
      "7: builders build houses, they put an emitter that has a 90-degree\n",
      "8: elbow on it and we'll recommend to replace that a midter with a clean\n",
      "9: out box so this can be a serviceable connection the homeowner\n",
      "10: keeps cleaned out. We also, the reason that we're here is this is\n",
      "11: overflowing and washing out this flower bed and that causes ice and\n",
      "12: things to come on this sidewalk in the winter time.\n",
      "13: We're here as this is overflowing and washing out this flower bed and it causes ice and things to come on this sidewalk in the winter time\n",
      "\n",
      "IMG_1396\n",
      "1: See you next time!\n",
      "\n",
      "IMG_1427\n",
      "1: See you next time!\n",
      "\n",
      "IMG_1432\n",
      "1: We are going to take a look at the other side of the building.\n",
      "2: We are going to take a look at the other side of the building.\n",
      "3: We are going to take a look at the other side of the building.\n",
      "4: We are going to take a look at the other side of the building.\n",
      "5: We are going to take a look at the other side of the building.\n",
      "\n",
      "IMG_1426\n",
      "1: A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-A-\n",
      "\n",
      "IMG_1397\n",
      "1: So, I think that's been very interesting.\n",
      "\n",
      "IMG_1383\n",
      "1: One thing I've noticed with these homes here, get ready to get me that out of the\n",
      "\n",
      "IMG_1381\n",
      "1: Okay, we're at a house here that was built in 2003 and looking at a problem that\n",
      "2: happens fairly common where you see a rain gutter downspout, come down the house, and\n",
      "3: goes into an underground drain.\n",
      "4: And this customer called this flower, but it's kind of washing out and we know that this\n",
      "5: drain is clogged.\n",
      "6: And what we're going to do is disconnect the downspout from the underground drain pipe.\n",
      "7: This is called ADS.\n",
      "8: And then we're going to run a jetter that'll go down that pipe.\n",
      "9: And it'll erode all of the clogging that's in there and we'll be able to locate it.\n",
      "10: Somewhere out in the grass.\n",
      "11: We don't know for sure where this is at.\n",
      "12: We can assume that it's somewhere in this area.\n",
      "13: And what we find is there's usually any meter that's a 90 degree\n",
      "14: elbow that turns up that allows water to come out there and what we'll\n",
      "15: recommend is to locate the emitter, remove the emitter and replace it with a\n",
      "16: clean out box so then the homeowner can service it and I have a clogged\n",
      "17: again.\n",
      "18: Thank you.\n",
      "\n",
      "IMG_1418\n",
      "1: There you go.\n",
      "2: So I don't know what the hell these guys from.\n",
      "\n",
      "IMG_1419\n",
      "1: So one thing about these drains that homeowners don't think about is this is overflowing\n",
      "2: and it's causing this dirt around the foundation to settle.\n",
      "3: It's right by the electrical line, and that's never good to have water and electricity\n",
      "4: together.\n",
      "5: And people just don't think about the maintenance of these underground drains for\n",
      "6: those reasons.\n",
      "7: It happens a lot.\n",
      "8: We see these underground drains a lot of a home was built in the early\n",
      "9: 2000s and it's been 20 years. It's 100% guarantee that these underground drains are clocked\n",
      "10: because they have been serviced and nobody's really thinking about it as it made inside them on their home.\n",
      "\n",
      "IMG_1425\n",
      "1: ご視聴ありがとうございました\n",
      "2: See you next time!\n",
      "\n",
      "IMG_1431\n",
      "1: See you next time!\n",
      "\n",
      "IMG_1384\n",
      "1: If you've gotten some film art at this but it's just a lazy.\n",
      "2: That's all being done here.\n",
      "3: That's why Matt and Amy's...\n",
      "4: Okay, so that's quite a cloud.\n",
      "5: So we're going to open that up and we'll put in a doctor on that so that that doesn't\n",
      "6: do that.\n",
      "\n",
      "IMG_1409\n",
      "1: Thank you for watching!\n",
      "\n",
      "IMG_1408\n",
      "1: You like the camera?\n",
      "2: Okay.\n",
      "3: you\n",
      "\n",
      "IMG_1437\n",
      "1: I'm gonna go to the bathroom.\n",
      "2: I'm gonna go to the bathroom.\n",
      "3: I'm gonna go to the bathroom.\n",
      "4: I'm gonna go to the bathroom.\n",
      "5: I'm gonna go to the bathroom.\n",
      "6: I'm gonna go to the bathroom.\n",
      "7: I'm gonna go to the bathroom.\n",
      "8: I'm gonna go to the bathroom.\n",
      "9: I'm gonna go to the bathroom.\n",
      "10: See this is what happens.\n",
      "11: One of the schools like this,\n",
      "12: you can use your own simulation.\n",
      "13: I'm gonna go to the bathroom.\n",
      "14: I'm gonna go to the bathroom.\n",
      "15: I want to disclose like this.\n",
      "16: Please, you have some information.\n",
      "17: I'm happy to have you.\n",
      "18: I'm happy to have you.\n",
      "Storyboard segments selected: \"{\\n  \\\"segments\\\": [\\n    {\\n      \\\"video\\\": \\\"IMG_1407\\\",\\n      \\\"idx\\\": 1\\n    },\\n    {\\n      \\\"video\\\": \\\"IMG_1399\\\",\\n      \\\"idx\\\": 3\\n    },\\n    {\\n      \\\"video\\\": \\\"IMG_1441\\\",\\n      \\\"idx\\\": 2\\n    },\\n    {\\n      \\\"video\\\": \\\"IMG_1444\\\",\\n      \\\"idx\\\": 1\\n    },\\n    {\\n      \\\"video\\\": \\\"IMG_1417\\\",\\n      \\\"idx\\\": 1\\n    },\\n    {\\n      \\\"video\\\": \\\"IMG_1405\\\",\\n      \\\"idx\\\": 1\\n    },\\n    {\\n      \\\"video\\\": \\\"IMG_1410\\\",\\n      \\\"idx\\\": 1\\n    }\\n  ]\\n}\"\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Load OpenAI API key from environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "def select_storyboard_segments(transcript_files, goal):\n",
    "    # Define the prompt for selecting relevant segments\n",
    "    transcripts = []\n",
    "    for transcript_file in transcript_files:\n",
    "        with open(transcript_file, 'r') as file:\n",
    "            transcript = json.load(file)\n",
    "            parsed_transcript = transcript_file.stem + \"\\n\" + \"\\n\".join(f\"{i}: {x['text']}\" for i, x in enumerate(transcript, start=1))\n",
    "            transcripts.append(parsed_transcript)\n",
    "\n",
    "    system_prompt = f\"\"\"You are producing a storyboard for a video with the following instruction: `{goal}`. Your goal is to select sentences from each of the given transcripts to stitch together into a final video.\\\n",
    "Return a json file with a list of tuples named `segments`, each containing a `video` field with the filename and a `idx` field with the index of the sentence in that video.\"\"\"\n",
    "    user_prompt = \"\\n\\n\".join(transcripts)\n",
    "    print(system_prompt)\n",
    "    print(user_prompt)\n",
    "    \n",
    "    # Get the response from GPT-4\n",
    "    response = client.chat.completions.create(\n",
    "\n",
    "    model=\"gpt-4o\",\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=0\n",
    "    )\n",
    "\n",
    "    relevant_segments = response.choices[0].message.content.strip()\n",
    "    \n",
    "    return relevant_segments\n",
    "\n",
    "# Define the high level goal\n",
    "high_level_goal = \"make an advertising video\"\n",
    "\n",
    "# Select relevant segments for the storyboard\n",
    "storyboard = json.loads(select_storyboard_segments(transcribed_files, high_level_goal))\n",
    "print(\"Storyboard segments selected:\", json.dumps(storyboard, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video final_output.mp4.\n",
      "MoviePy - Writing audio in final_outputTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video final_output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready final_output.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "import json\n",
    "\n",
    "#storyboard = json.loads(storyboard)\n",
    "\n",
    "# List to hold video clips\n",
    "clips = []\n",
    "\n",
    "# Process each segment\n",
    "for segment in storyboard['segments']:\n",
    "    video_file = f\"data/{segment['video']}.MOV\"\n",
    "    transcript_file = f\"data/transcripts/{segment['video']}.json\"\n",
    "    \n",
    "    # Load the transcript data\n",
    "    with open(transcript_file, 'r') as file:\n",
    "        transcript = json.load(file)\n",
    "    \n",
    "    # Get the start and end times for the clip\n",
    "    clip_info = transcript[segment['idx'] - 1]  # Adjust index since JSON is 0-indexed\n",
    "    start_time = clip_info['start']\n",
    "    end_time = clip_info['end']\n",
    "    \n",
    "    # Load the video clip from start to end times\n",
    "    video_clip = VideoFileClip(video_file).subclip(start_time, end_time)\n",
    "    clips.append(video_clip)\n",
    "\n",
    "# Concatenate all clips into one final video\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "final_clip.write_videofile(\"final_output.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
