# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_transcription.ipynb.

# %% auto 0
__all__ = ['MODEL_SIZE', 'example_transcript', 'whisper_jax_pipeline', 'transcript', 'device', 'model', 'Word', 'Phrase',
           'Transcript', 'pretty_print_transcript', 'transcribe_with_whisper_jax',
           'transcribe_with_whisper_timestamped']

# %% ../nbs/01_transcription.ipynb 3
import json

# size of the whisper model to use, tiny is good for validation
MODEL_SIZE = "tiny"

# %% ../nbs/01_transcription.ipynb 4
from pydantic import BaseModel
from typing import List

class Word(BaseModel):
    start: float | None
    end: float | None
    text: str
    confidence: float

class Phrase(BaseModel):
    start: float
    end: float
    words: List[Word]
    confidence: float

class Transcript(BaseModel):
    phrases: List[Phrase]

# %% ../nbs/01_transcription.ipynb 5
example_transcript = Transcript(
    phrases=[
        Phrase(
            start=0.0,
            end=2.5,
            words=[
                Word(start=0.0, end=0.5, text="Hello", confidence=0.95),
                Word(start=0.6, end=1.2, text="world", confidence=0.98),
                Word(start=1.3, end=2.5, text="testing", confidence=0.92)
            ],
            confidence=0.96
        ),
        Phrase(
            start=3.0,
            end=5.0,
            words=[
                Word(start=3.0, end=3.5, text="another", confidence=0.93),
                Word(start=3.6, end=4.2, text="phrase", confidence=0.89),
                Word(start=4.3, end=5.0, text="here", confidence=0.94)
            ],
            confidence=0.93
        )
    ]
)

# %% ../nbs/01_transcription.ipynb 7
def pretty_print_transcript(transcript: Transcript):
    for i, phrase in enumerate(transcript.phrases, start=1):
        print(f"{i}: [{phrase.start}-{phrase.end}] ({phrase.confidence}) {' '.join(word.text for word in phrase.words)}")
        for word in phrase.words:
            if word.confidence < 0.9:
                print(f"  {word.text} ({word.confidence})")

pretty_print_transcript(example_transcript)

# %% ../nbs/01_transcription.ipynb 9
from whisper_jax import FlaxWhisperPipline
import jax.numpy as jnp

whisper_jax_pipeline = FlaxWhisperPipline(f"openai/whisper-{MODEL_SIZE}", dtype=jnp.bfloat16)



# %% ../nbs/01_transcription.ipynb 10
def transcribe_with_whisper_jax(audio_path: str, **kwargs) -> Transcript:
    transcript = whisper_jax_pipeline(audio_path, return_timestamps=True, **kwargs)['chunks']
    return Transcript(phrases = [
        Phrase(start=chunk['timestamp'][0], end=chunk['timestamp'][1] if chunk['timestamp'][1] else -1, 
            words=[
                Word(start=None, end=None, text=word, confidence=1)
                for word in chunk['text'].strip().split()
            ],
            confidence=1
        )
        for chunk in transcript
    ])

transcript = transcribe_with_whisper_jax("../data/transcribe_test.mp3")
pretty_print_transcript(transcript)



# %% ../nbs/01_transcription.ipynb 12
import whisper_timestamped as whisper
import jax

# Check if GPU is available and set the device accordingly
device = "gpu" if jax.local_devices()[0].device_kind == "GPU" else "cpu"
model = whisper.load_model(MODEL_SIZE, device=device)

# %% ../nbs/01_transcription.ipynb 13
def transcribe_with_whisper_timestamped(audio_path: str, **kwargs) -> Transcript:
    audio = whisper.load_audio(audio_path)
    transcript = whisper.transcribe(model, audio, language="en", vad="auditok", **kwargs)['segments']
    return Transcript(phrases=[
        Phrase(start=segment['start'], end=segment['end'], confidence=segment['confidence'],
            words=[
                Word(start=word['start'], end=word['end'], text=word['text'], confidence=word['confidence'])
                for word in segment["words"]
            ]
        )
        for segment in transcript
    ])

transcript = transcribe_with_whisper_timestamped("../data/transcribe_test.mp3")
pretty_print_transcript(transcript)
