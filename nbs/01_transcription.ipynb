{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "\n",
    "# size of the whisper model to use, tiny is good for validation\n",
    "MODEL_SIZE = \"tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Word(BaseModel):\n",
    "    start: float | None\n",
    "    end: float | None\n",
    "    text: str\n",
    "    confidence: float\n",
    "\n",
    "class Phrase(BaseModel):\n",
    "    start: float\n",
    "    end: float\n",
    "    words: List[Word]\n",
    "    confidence: float\n",
    "\n",
    "class Transcript(BaseModel):\n",
    "    phrases: List[Phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "example_transcript = Transcript(\n",
    "    phrases=[\n",
    "        Phrase(\n",
    "            start=0.0,\n",
    "            end=2.5,\n",
    "            words=[\n",
    "                Word(start=0.0, end=0.5, text=\"Hello\", confidence=0.95),\n",
    "                Word(start=0.6, end=1.2, text=\"world\", confidence=0.98),\n",
    "                Word(start=1.3, end=2.5, text=\"testing\", confidence=0.92)\n",
    "            ],\n",
    "            confidence=0.96\n",
    "        ),\n",
    "        Phrase(\n",
    "            start=3.0,\n",
    "            end=5.0,\n",
    "            words=[\n",
    "                Word(start=3.0, end=3.5, text=\"another\", confidence=0.93),\n",
    "                Word(start=3.6, end=4.2, text=\"phrase\", confidence=0.89),\n",
    "                Word(start=4.3, end=5.0, text=\"here\", confidence=0.94)\n",
    "            ],\n",
    "            confidence=0.93\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| epxort\n",
    "from pydantic import TypeAdapter\n",
    "\n",
    "TranscriptHandler = TypeAdapter(Transcript)\n",
    "\n",
    "def dump_transcript_to_json(transcript: Transcript, file_path: str):\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(transcript.model_dump_json(indent=2))\n",
    "\n",
    "def load_transcript_from_json(file_path: str) -> Transcript:\n",
    "    with open(\"test.json\", \"r\") as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    # Validate the JSON data using the handler\n",
    "    validated_transcript = TranscriptHandler.validate_python(json_data)\n",
    "    return validated_transcript\n",
    "\n",
    "dump_transcript_to_json(example_transcript, \"../test.json\")\n",
    "deserialized_transcript = load_transcript_from_json(\"../test.json\")\n",
    "\n",
    "assert example_transcript == deserialized_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [0.0-2.5] (0.96) Hello world testing\n",
      "2: [3.0-5.0] (0.93) another phrase here\n",
      "  phrase (0.89)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def pretty_print_transcript(transcript: Transcript):\n",
    "    for i, phrase in enumerate(transcript.phrases, start=1):\n",
    "        print(f\"{i}: [{phrase.start}-{phrase.end}] ({phrase.confidence}) {' '.join(word.text for word in phrase.words)}\")\n",
    "        for word in phrase.words:\n",
    "            if word.confidence < 0.9:\n",
    "                print(f\"  {word.text} ({word.confidence})\")\n",
    "\n",
    "pretty_print_transcript(example_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper JAX\n",
    "\n",
    "This should be super fast on GPU. Doesn't have much of a perf advantage on CPU and produces phrase-level timestamps so a bit awkward for captioning. Could potentially implement the dynamic time-warping work or use some sort of forced aligner.\n",
    "\n",
    "Due to the wonders of JAX, pipeline needs to be run once for JIT. Subsequent runs will be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from whisper_jax import FlaxWhisperPipline\n",
    "import jax.numpy as jnp\n",
    "\n",
    "whisper_jax_pipeline = FlaxWhisperPipline(f\"openai/whisper-{MODEL_SIZE}\", dtype=jnp.bfloat16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [0.0-4.4] (1.0) In the last chapter, you and I started to step through the internal workings of a transformer.\n",
      "2: [4.4-10.8] (1.0) This is one of the key pieces of technology inside large language models, and a lot of other tools in the modern way of AI.\n",
      "3: [10.8-15.52] (1.0) It first hit the scene and a now famous 2017 paper called Attention as All You Need,\n",
      "4: [15.52-19.6] (1.0) and in this chapter, you and I will dig into what this attention mechanism is,\n",
      "5: [19.6-21.6] (1.0) visualizing how it processes data.\n",
      "6: [26.48-30.12] (1.0) As a quick recap, here's the important context I want you to have in mind.\n",
      "7: [30.12-34.68] (1.0) The goal of the model that you and I are studying is to take in a piece of text and predict\n",
      "8: [34.68-36.8] (1.0) what word comes next.\n",
      "9: [36.8-41.04] (1.0) The input text is broken up into little pieces that we call tokens, and these are very\n",
      "10: [41.04-47.0] (1.0) often words or pieces of words, but just to make the examples in this video easier for you and me to think about,\n",
      "11: [47.0-51.0] (1.0) let's simplify by pretending that tokens are always just words.\n",
      "12: [51.0-58.0] (1.0) The first step in a transformer is to associate each token with a high dimensional vector, what we call its embedding.\n",
      "13: [58.0--1.0] (1.0) Now the most important idea I want you to have in the world is to have a simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple, simple,\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def transcribe_with_whisper_jax(audio_path: str, **kwargs) -> Transcript:\n",
    "    transcript = whisper_jax_pipeline(audio_path, return_timestamps=True, **kwargs)['chunks']\n",
    "    return Transcript(phrases = [\n",
    "        Phrase(start=chunk['timestamp'][0], end=chunk['timestamp'][1] if chunk['timestamp'][1] else -1, \n",
    "            words=[\n",
    "                Word(start=None, end=None, text=word, confidence=1)\n",
    "                for word in chunk['text'].strip().split()\n",
    "            ],\n",
    "            confidence=1\n",
    "        )\n",
    "        for chunk in transcript\n",
    "    ])\n",
    "\n",
    "transcript = transcribe_with_whisper_jax(\"../data/transcribe_test.mp3\")\n",
    "pretty_print_transcript(transcript)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper Timestamped\n",
    "\n",
    "[Documentation](https://github.com/linto-ai/whisper-timestamped)\n",
    "\n",
    "Uses dynamic time warping to generate timestamps for every word.\n",
    "Runs faster than JAX on CPU but does so by forsaking beam decoding. Might be problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper_timestamped as whisper\n",
    "import jax\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = \"gpu\" if jax.local_devices()[0].device_kind == \"GPU\" else \"cpu\"\n",
    "model = whisper.load_model(MODEL_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5998/5998 [00:03<00:00, 1738.12frames/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [0.08-4.0] (0.91) In the last chapter, you and I started to step through the internal workings of a transformer.\n",
      "  you (0.559)\n",
      "  started (0.896)\n",
      "  workings (0.837)\n",
      "  transformer. (0.829)\n",
      "2: [4.5-7.64] (0.968) This is one of the key pieces of technology inside large language models,\n",
      "  language (0.817)\n",
      "3: [7.96-10.3] (0.973) and a lot of other tools in the modern way of AI.\n",
      "  way (0.79)\n",
      "4: [10.96-15.24] (0.8) It first hit the scene and a now famous 2017 paper called Attention as All You Need,\n",
      "  and (0.43)\n",
      "  famous (0.435)\n",
      "  Attention (0.773)\n",
      "  as (0.366)\n",
      "  You (0.695)\n",
      "5: [15.66-19.54] (0.974) and in this chapter, you and I will dig into what this attention mechanism is,\n",
      "  attention (0.813)\n",
      "6: [19.74-21.58] (0.978) visualizing how it processes data.\n",
      "7: [26.36-29.48] (0.957) As a quick recap, here's the important context I want you to have in mind.\n",
      "  As (0.598)\n",
      "8: [30.08-33.88] (0.969) The goal of the model that you and I are studying is to take in a piece of text\n",
      "  is (0.775)\n",
      "9: [34.04-35.96] (0.977) and predict what word comes next.\n",
      "  word (0.877)\n",
      "10: [36.72-40.02] (0.969) The input text is broken up into little pieces that we call tokens,\n",
      "  tokens, (0.811)\n",
      "11: [40.58-43.14] (0.988) and these are very often words or pieces of words,\n",
      "12: [43.44-46.96] (0.989) but just to make the examples in this video easier for you and me to think about,\n",
      "13: [47.14-50.48] (0.99) let's simplify by pretending that tokens are always just words.\n",
      "14: [51.34-56.1] (0.934) The first step in a transformer is to associate each token with a high-dimensional vector,\n",
      "  with (0.626)\n",
      "  high-dimensional (0.845)\n",
      "  vector, (0.891)\n",
      "15: [56.38-57.74] (0.881) what we call its embedding.\n",
      "  what (0.743)\n",
      "  its (0.653)\n",
      "16: [58.14-60.24] (0.925) Now the most important idea I want you to have in mind.\n",
      "  the (0.701)\n",
      "  in (0.691)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "def transcribe_with_whisper_timestamped(audio_path: str, **kwargs) -> Transcript:\n",
    "    audio = whisper.load_audio(audio_path)\n",
    "    transcript = whisper.transcribe(model, audio, language=\"en\", vad=\"auditok\", **kwargs)['segments']\n",
    "    return Transcript(phrases=[\n",
    "        Phrase(start=segment['start'], end=segment['end'], confidence=segment['confidence'],\n",
    "            words=[\n",
    "                Word(start=word['start'], end=word['end'], text=word['text'], confidence=word['confidence'])\n",
    "                for word in segment[\"words\"]\n",
    "            ]\n",
    "        )\n",
    "        for segment in transcript\n",
    "    ])\n",
    "\n",
    "transcript = transcribe_with_whisper_timestamped(\"../data/transcribe_test.mp3\")\n",
    "pretty_print_transcript(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "transcribe = lambda audio_path, **kwargs: transcribe_with_whisper_timestamped(audio_path, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
